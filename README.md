# KepKreator

<div align="center">

**Handwritten Character Generation with Conditional Generative Adversarial Networks**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FokaKefir/KepKreator)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[Demo](#demo) ‚Ä¢ [Installation](#installation) ‚Ä¢ [Features](#features) ‚Ä¢ [Documentation](#documentation) ‚Ä¢ [Citation](#citations)

</div>



## Overview

**KepKreator** is an advanced deep learning project that generates realistic handwritten characters (digits and letters) using Conditional Generative Adversarial Networks (cGANs). The system learns from the MNIST and EMNIST datasets to produce high-quality synthetic handwriting that can be conditioned on specific character labels.

### üéØ Key Highlights

- **State-of-the-art Architecture**: Implements conditional GANs with optimized generator and discriminator networks
- **Dual-Model System**: Separate specialized models for digits (0-9) and letters (A-Z)
- **Advanced Evaluation Metrics**: Custom implementation of Inception Score (IS), Between-Class Inception Score (BCIS), and Within-Class Inception Score (WCIS)
- **Hyperparameter Optimization**: Automated tuning using Keras Tuner with RandomSearch and Hyperband algorithms
- **Production-Ready API**: FastAPI-based REST API with CORS support for seamless integration
- **Interactive Web Interface**: User-friendly frontend for real-time character generation

### üë• Team Members

| Name | Neptun Code | Institution |
|---|-------------|-------------|
| **Asz√≥di Zsombor** | XJ43M0 | Budapest University of Technology and Economics |
| **Babos D√°vid** | Q1CGY7 | Faculty of Electrical Engineering and Informatics |
| **Kov√°cs Gergely** | JWV9WR | Deep Learning in Practice with Python and LUA |



## Table of Contents

- [Demo](#demo)
- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Model Training](#model-training)
- [Evaluation Metrics](#evaluation-metrics)
- [Hyperparameter Optimization](#hyperparameter-optimization)
- [API Documentation](#api-documentation)
- [Results](#results)
- [Future Work](#future-work)
- [Documentation](#documentation)
- [Citations](#citations)
- [License](#license)



## Demo

![Example Generation](docs/example.jpg)

The web interface allows users to input any combination of letters and numbers, and the system generates corresponding handwritten characters in real-time.

**Live Demo Features:**
- ‚úçÔ∏è Generate custom handwritten text
- üîÑ Real-time image synthesis
- üìä Support for alphanumeric characters
- üíæ Automatic image saving and retrieval



## Features

### ü§ñ Core Capabilities

- **Conditional Image Generation**: Generate handwritten characters conditioned on specific class labels
- **High-Quality Synthesis**: Produces realistic 28√ó28 grayscale images matching handwriting characteristics
- **Label Embedding**: Advanced embedding layers for effective conditioning
- **Stable Training**: Tanh activation functions and optimized learning rates for training stability

### üìä Advanced Metrics

- **Inception Score (IS)**: Measures quality and diversity of generated images
- **Between-Class Inception Score (BCIS)**: Evaluates class separation and coverage
- **Within-Class Inception Score (WCIS)**: Assesses intra-class diversity
- **Custom Validation CNN**: Purpose-built classifier with 99%+ accuracy for metric computation

### üõ†Ô∏è Technical Features

- **Object-Oriented Design**: Modular, maintainable codebase with custom Keras Model classes
- **Memory Optimization**: Efficient resource management for large-scale training
- **Batch Processing**: Supports variable batch sizes (tested with 32, 64, 128)
- **Model Checkpointing**: Automatic saving of best models during training
- **WandB Integration**: Comprehensive experiment tracking and visualization



## Architecture

### Conditional GAN Framework

The system consists of two competing neural networks trained simultaneously:

#### **Generator Network**
- **Input**: Latent vector (dimension: 64-128) + class label
- **Architecture**:
  - Label embedding layer (10-50 dimensions)
  - Fully connected layers with Tanh activation
  - Transpose convolutional layers for upsampling (7√ó7 ‚Üí 14√ó14 ‚Üí 28√ó28)
  - Output: 28√ó28√ó1 grayscale image (pixel values: -1 to +1)

#### **Discriminator Network**
- **Input**: 28√ó28 image + class label
- **Architecture**:
  - Label embedding concatenated with image
  - Convolutional layers with Tanh activation (32-128 filters)
  - Fully connected layers for classification
  - Output: Binary probability (real vs. fake)

#### **Training Strategy**
- **Optimizer**: Adam (learning rate: 0.0002, Œ≤‚ÇÅ: 0.5)
- **Loss Function**: Binary cross-entropy
- **Training Loop**: Alternating discriminator and generator updates
- **Batch Size**: 32 (optimal balance between speed and quality)



## Installation

### Prerequisites

- Python 3.8 or higher
- TensorFlow 2.x
- CUDA-compatible GPU (recommended for training)

### Quick Start

1. **Clone the Repository**
   ```bash
   git clone https://github.com/FokaKefir/KepKreator.git
   cd KepKreator
   ```

2. **Set Up Python Environment** (recommended)
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Dependencies**
   ```bash
   cd app
   pip install -r requirements.txt
   ```

4. **Launch the API Server**
   
   **On Linux/macOS/Git Bash:**
   ```bash
   ./start.sh
   ```
   
   **On Windows (PowerShell/CMD):**
   ```bash
   uvicorn generate:app --reload
   ```

5. **Access the Web Interface**
   
   Wait for the `Ready to go!` message, then open `web/index.html` in your browser.

6. **Stop the Server**
   
   Press `Ctrl+C` in the terminal.



## Usage

### Web Interface

1. Navigate to the web interface by opening `app/web/index.html`
2. Enter any alphanumeric text (e.g., "Hello123")
3. Click "Generate" to create handwritten characters
4. View and download the generated image

### API Usage

**Endpoint**: `GET /generate/{text}`

**Example Request**:
```bash
curl http://localhost:8000/generate/Hello2024
```

**Response**:
```json
{
  "image_path": "images/Hello2024_1234567890.png",
  "characters_generated": 9
}
```

### Python API

```python
from models import CGAN
import numpy as np

# Load pre-trained model
cgan = CGAN(latent_dim=96, n_classes=10)
cgan.load_models('models/num-model/generator.h5', 
                 'models/num-model/discriminator.h5')

# Generate specific digits
labels = np.array([3, 1, 4, 1, 5]).reshape(-1, 1)
images = cgan.generate_images(labels)
```



## Project Structure

```
KepKreator/
‚îú‚îÄ‚îÄ app/                          # Production application
‚îÇ   ‚îú‚îÄ‚îÄ generate.py               # FastAPI server
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # CGAN model class
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ start.sh                  # Launch script
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Pre-trained models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ num-model/            # Digit generator (0-9)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator.h5
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ discriminator.h5
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ letter-model-zs/      # Letter generator (A-Z)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ generator.h5
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ discriminator.h5
‚îÇ   ‚îî‚îÄ‚îÄ web/                      # Frontend interface
‚îÇ       ‚îú‚îÄ‚îÄ index.html
‚îÇ       ‚îî‚îÄ‚îÄ script.js
‚îú‚îÄ‚îÄ docs/                         # Academic documentation
‚îÇ   ‚îú‚îÄ‚îÄ Documentation.pdf         # Complete IEEE-format paper
‚îÇ   ‚îî‚îÄ‚îÄ Documentation.tex         # LaTeX source
‚îú‚îÄ‚îÄ MNIST_GAN.ipynb              # Main training notebook (digits)
‚îú‚îÄ‚îÄ EMNIST_GAN.ipynb             # Letter training notebook
‚îú‚îÄ‚îÄ MNIST_preprocess.ipynb       # MNIST data preprocessing
‚îú‚îÄ‚îÄ EMNIST_preprocess.ipynb      # EMNIST data preprocessing
‚îú‚îÄ‚îÄ MNIST2_preprocess.ipynb      # Multi-digit preprocessing
‚îú‚îÄ‚îÄ MNIST_val_model.ipynb        # Validation CNN training
‚îú‚îÄ‚îÄ validation_cnn.hdf5          # Pre-trained validation model
‚îî‚îÄ‚îÄ README.md                    # This file
```



## Model Training

### Training the MNIST Model

Open `MNIST_GAN.ipynb` in Jupyter or Google Colab:

```python
# Configure hyperparameters
config = {
    'latent_dim': 96,
    'gen_label_embedding': 10,
    'gen_label_hidden': 8,
    'gen_input_hidden': 96,
    'gen_conv1_channels': 64,
    'gen_conv2_channels': 64,
    'disc_label_embedding': 10,
    'disc_conv1_channels': 64,
    'disc_conv2_channels': 128,
    'disc_dense_hidden': 128,
    'n_classes': 10,
    'epochs': 100,
    'batch_size': 32
}

# Initialize and compile model
cgan = CGAN(config)
cgan.compile(
    d_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),
    g_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),
    loss_fn=BinaryCrossentropy(from_logits=False)
)

# Train with callbacks
cgan.fit(x_train, labels_train, 
         epochs=config['epochs'],
         batch_size=config['batch_size'],
         validation_data=[x_test[0]],
         callbacks=[checkpointer, sampler, wandb_callback])
```

### Training the EMNIST Model

Open `EMNIST_GAN.ipynb` for letter generation with similar configuration.

### Data Preprocessing

- **`MNIST_preprocess.ipynb`**: Load and normalize MNIST digits
- **`EMNIST_preprocess.ipynb`**: Process EMNIST letters dataset
- **`MNIST2_preprocess.ipynb`**: Create multi-digit combinations



## Evaluation Metrics

### Custom Validation Model

A lightweight CNN classifier (`MNIST_val_model.ipynb`) was trained to evaluate generated images:

- **Architecture**: 3 conv blocks with batch normalization and max pooling
- **Accuracy**: >99% on MNIST test set
- **Purpose**: Compute probability distributions for IS/BCIS/WCIS metrics

### Inception Score (IS)

Measures both quality and diversity:

```
IS(X;Y) = exp{ E[D_KL(p_G(y|x) || p_G(y))] }
```

**Higher is better** - indicates sharp class predictions with diverse outputs.

### Between-Class Inception Score (BCIS)

Evaluates class separation:

```
BCIS(X;Y) = exp{ E[D_KL(p_G(y|C) || p_G(y))] }
```

**Higher is better** - shows distinct class representation across conditions.

### Within-Class Inception Score (WCIS)

Measures intra-class diversity:

```
WCIS(X;Y) = exp{ E[I(X_C; Y_C)] }
```

**Lower is better** - indicates focused generation within conditioned classes.



## Hyperparameter Optimization

The project employs Keras Tuner for systematic hyperparameter search:

### Search Space

- **Latent dimension**: [32, 64, 96, 128]
- **Embedding sizes**: [10, 25, 50]
- **Hidden units**: [1, 4, 8, 16, 32, 64, 96, 128]
- **Convolutional filters**: [16, 64, 128, 256]
- **Batch normalization**: [True, False]

### Optimization Strategy

```python
tuner = keras_tuner.RandomSearch(
    CGANHypermodel(),
    objective=keras_tuner.Objective('val_within_class_inception_score', 'min'),
    max_trials=20,
    directory='hyperparam_tuning',
    project_name='KepKreator'
)
```

### Key Findings

- **Training duration** is the most critical factor for quality
- **Batch size 32** provides optimal balance between speed and stability
- **100+ epochs** required for convergence to high-quality outputs
- **Tanh activation** outperforms LeakyReLU for this architecture
- **No batch normalization** yields better discriminator-generator balance



## API Documentation

### Endpoints

#### Generate Handwritten Text
```
GET /generate/{text}
```

**Parameters:**
- `text` (path, required): Alphanumeric string to generate

**Response:**
```json
{
  "image_path": "images/example_timestamp.png",
  "success": true
}
```

**Validation:**
- Only alphanumeric characters (A-Z, a-z, 0-9)
- Returns HTTP 422 for invalid characters

### Models

#### CGAN Class

**Methods:**
- `load_models(generator_path, discriminator_path)`: Load pre-trained weights
- `generate_images(labels)`: Generate images for specific labels
- `generate_latent_points(n_samples)`: Sample from latent space
- `build_generator(latent_dim, n_classes)`: Construct generator network
- `build_discriminator(n_classes)`: Construct discriminator network



## Results

### Training Progress

| Epoch | IS ‚Üë | BCIS ‚Üë | WCIS ‚Üì | Quality |
|-------|------|--------|--------|---------|
| 1     | 2.1  | 3.2    | 8.7    | Noise   |
| 10    | 4.5  | 5.8    | 3.2    | Shapes forming |
| 50    | 7.2  | 8.1    | 1.8    | Recognizable |
| 100   | 8.9  | 9.3    | 1.2    | High quality |

### Performance Characteristics

- **Generation Time**: <50ms per character (GPU)
- **Model Size**: ~15MB per model (generator + discriminator)
- **Training Time**: ~40 minutes per 10 epochs (batch size 32, GPU)
- **Discriminator Accuracy**: Real: 85-90%, Fake: 80-85%

### Sample Outputs

Training progression shows continuous improvement:
- **Early epochs**: Random noise patterns
- **Mid-training**: Recognizable digit/letter shapes
- **Late training**: Clean, realistic handwritten characters



## Future Work

### Short-term Goals
- ‚úÖ Improve label conditioning accuracy
- ‚úÖ Extend EMNIST model to full 62-class byclass dataset
- ‚úÖ Implement progressive growing techniques
- ‚úÖ Add style transfer capabilities

### Long-term Vision
- üîÑ Explore diffusion models for higher quality
- üîÑ Multi-character sequence generation
- üîÑ User-specific handwriting style adaptation
- üîÑ Mobile application deployment



## Documentation

üìÑ **[Complete Academic Documentation (PDF)](docs/Documentation.pdf)**

The IEEE-format paper provides comprehensive coverage of:
- Theoretical foundations of GANs and cGANs
- Detailed architecture specifications
- Mathematical formulations of evaluation metrics
- Experimental results and analysis
- Comparative studies and ablation tests



## Citations

### Datasets

1. **MNIST Database**  
   LeCun, Y., Cortes, C., & Burges, C.J.C. "THE MNIST DATABASE of handwritten digits."  
   Courant Institute, NYU; Google Labs; Microsoft Research.  
   Available: http://yann.lecun.com/exdb/mnist/

2. **EMNIST Dataset**  
   Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017).  
   "EMNIST: an extension of MNIST to handwritten letters."  
   arXiv:1702.05373  
   Available: http://arxiv.org/abs/1702.05373

### Key References

3. **Generative Adversarial Networks**  
   Goodfellow, I.J., et al. (2014). "Generative adversarial nets." NIPS'2014.  
   arXiv:1406.2661

4. **Conditional GANs**  
   Mirza, M., & Osindero, S. (2014). "Conditional Generative Adversarial Nets."  
   arXiv:1411.1784

5. **DCGAN Architecture**  
   Radford, A., Metz, L., & Chintala, S. (2015).  
   "Unsupervised Representation Learning with Deep Convolutional GANs."  
   arXiv:1511.06434

6. **Conditional Evaluation Metrics**  
   Benny, Y., et al. (2021). "Evaluation metrics for conditional image generation."  
   International Journal of Computer Vision, 129, 1712-1731.



## License

This project is licensed under the MIT License - see the LICENSE file for details.



## Acknowledgments

This project was developed as part of the **Deep Learning in Practice with Python and LUA** course at the **Budapest University of Technology and Economics**, Faculty of Electrical Engineering and Informatics.

Special thanks to the course instructors and the open-source community for providing essential tools and datasets.



<div align="center">

**Made with ‚ù§Ô∏è by the KepKreator Team**

[Report Bug](https://github.com/FokaKefir/KepKreator/issues) ‚Ä¢ [Request Feature](https://github.com/FokaKefir/KepKreator/issues)

</div>
