{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FokaKefir/KepKreator/blob/main/MNIST_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftjFo_hAlKB1",
        "outputId": "543cf01b-2599-4cd9-bd6e-8d9fdbaae182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n",
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.6 kt-legacy-1.0.5\n",
            "Cloning into 'KepKreator'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 222 (delta 16), reused 34 (delta 10), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (222/222), 20.40 MiB | 7.98 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment when running in colab\n",
        "!pip install wandb\n",
        "!pip install keras_tuner\n",
        "!git clone https://github.com/FokaKefir/KepKreator.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOixpLNLNLj5"
      },
      "source": [
        "# Import dependecies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7I59B7OvNDTP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, Input, Flatten, Reshape, Embedding, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import load_model, save_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import wandb\n",
        "import sys, os\n",
        "\n",
        "VAL_MODEL_PATH = '/content/KepKreator/validation_cnn.hdf5' # '/kaggle/working/KepKreator/validation_cnn.hdf5'\n",
        "PROJECT = 'KepKreator'\n",
        "WANDB_IMAGE_NUM = 8\n",
        "VAL_METRIC_N_SAMPLE = 1024\n",
        "USE_WANDB = False # True: during training\n",
        "N_CLASSES = 10\n",
        "\n",
        "# disable warnings\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "if USE_WANDB:\n",
        "    wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvAsA8tPhe_B"
      },
      "source": [
        "# Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BJrSWPQSG4h"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaYBacb7NKv9",
        "outputId": "57fd5ebb-759b-473c-85cd-50500a480901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, labels_train), (x_test, labels_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0 * 2 - 1, x_test / 255.0 * 2 - 1\n",
        "x_train = np.concatenate([x_train, x_test])\n",
        "labels_train = np.concatenate([labels_train, labels_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekU665vsSN0S"
      },
      "source": [
        "## Plot some random examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "hsozFwtXOaW4",
        "outputId": "29f8092e-d8d6-4ed4-996b-7c06ad31510c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8YAAAPeCAYAAADOFAM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKMklEQVR4nO3deZgV1Jkn/vdCoTCgIARcQaRdIkajERQYlSIuaKMJRpZEM4aEqFF7oiChE1utwmg7GlHiEmXimoiDgmjsAbUzQvloHhaJ0WkScSGCuKAsgpoIinV/f2Tk14TFQ9WtulV1Pp/n4Y9cvvect4rKsb51blUVisViMQAAACBTrco9AAAAAJSTYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYkydLF26NAqFQlx//fUlW7OmpiYKhULU1NSUbE2AxuZ8BNg65yNNmWKckXvuuScKhUIsXLiw3KM0iJ49e0ahUNjqnwMOOKDc4wFNWEs/H2fMmBEjR46MXr16xX/5L/8lDjrooLjkkkti7dq15R4NaOJa+vn4mQceeCD69+8f7du3j06dOsWAAQNi9uzZ5R6LRlRR7gGgVCZNmhQffvjhZo8tW7YsLrvssjjppJPKNBVA+Z177rmx1157xbe//e3o0aNH/Md//EfccsstMWvWrHjuueeiXbt25R4RoGyqq6vjyiuvjGHDhsWoUaPik08+iUWLFsWbb75Z7tFoRIoxLcbQoUO3eOyqq66KiIizzjqrkacBaDqmT58elZWVmz125JFHxne+852YMmVKfP/73y/PYABlNm/evLjyyitj4sSJMWbMmHKPQxl5KTWb+fjjj+OKK66II488Mjp27Bjt27ePY489NubMmbPN59x4442x7777Rrt27WLgwIGxaNGiLTKLFy+OYcOGRefOnaNt27bRp0+fePTRRz93nr/+9a+xePHiWLVqVZ3envvvvz/222+/GDBgQJ2eD/CZ5nw+/n0pjog4/fTTIyLixRdf/NznA2xPcz4fJ02aFHvssUdcdNFFUSwWt3j1IflQjNnM+++/H3fccUdUVlbGtddeG9XV1bFy5coYPHhwPP/881vkf/WrX8VNN90UF154YfzkJz+JRYsWxVe/+tV45513NmX++Mc/Rr9+/eLFF1+MH//4xzFx4sRo3759DB06NB5++OHtzrNgwYI4+OCD45Zbbtnht+UPf/hDvPjii3HmmWfu8HMB/l5LOh8jIlasWBEREV/4whfq9HyAzzTn8/HJJ5+Mvn37xk033RRdu3aNXXbZJfbcc886n600Y0Wycffddxcjovjss89uM7Nx48bihg0bNnvsvffeK+6+++7F733ve5see+2114oRUWzXrl3xjTfe2PT4/PnzixFRHDNmzKbHjj/++OKhhx5aXL9+/abHamtriwMGDCgecMABmx6bM2dOMSKKc+bM2eKxqqqqHX57L7nkkmJEFP/0pz/t8HOBvOR2PhaLxeLo0aOLrVu3Lr788st1ej6Qh5Z8Pq5Zs6YYEcUuXboUO3ToUPzZz35WfOCBB4onn3xyMSKKt99++3afT8vixpjNtG7dOnbaaaeIiKitrY01a9bExo0bo0+fPvHcc89tkR86dGjsvffem/73UUcdFUcffXTMmjUrIiLWrFkTs2fPjhEjRsQHH3wQq1atilWrVsXq1atj8ODB8corr2z3BxtUVlZGsViM6urqHXo7amtrY+rUqXHEEUfEwQcfvEPPBdialnI+Rvzt20zuvPPOuOSSS/zUfqDemuv5+NnLplevXh133HFHjBs3LkaMGBEzZ86M3r17b/pZNeRBMWYL9957bxx22GHRtm3b6NKlS3Tt2jVmzpwZ69at2yK7tU+oDjzwwFi6dGlERLz66qtRLBbj8ssvj65du272p6qqKiIi3n333ZK/DU899VS8+eabfugWUFIt4Xx8+umnY/To0TF48OC4+uqrS74+kKfmeD5+9hP527RpE8OGDdv0eKtWrWLkyJHxxhtvxOuvv17vfWge/FRqNnPffffFqFGjYujQofGjH/0ounXrFq1bt45rrrkmlixZssPr1dbWRkTEuHHjYvDgwVvN7L///vWaeWumTJkSrVq1im9961slXxvIU0s4H1944YX42te+Fl/60pdi+vTpUVHh0wCg/prr+fjZD/Xq1KlTtG7derO/69atW0REvPfee9GjR49670XT57+IbGb69OnRq1evmDFjRhQKhU2Pf/bVub/3yiuvbPHYyy+/HD179oyIiF69ekXE374Sd8IJJ5R+4K3YsGFDPPTQQ1FZWRl77bVXo+wJtHzN/XxcsmRJnHzyydGtW7eYNWtWdOjQocH3BPLQXM/HVq1axeGHHx7PPvtsfPzxx5teDh4R8dZbb0VERNeuXRtsf5oWL6VmM599taxYLG56bP78+TF37tyt5h955JHNvsdjwYIFMX/+/DjllFMi4m9fbausrIzJkyfH22+/vcXzV65cud156vLrmmbNmhVr1671MmqgpJrz+bhixYo46aSTolWrVvHEE0/4RA8oqeZ8Po4cOTI+/fTTuPfeezc9tn79+pgyZUr07t3bJUtG3Bhn6K677orHH398i8cvuuiiOPXUU2PGjBlx+umnx5AhQ+K1116L22+/PXr37r3V3+u2//77xzHHHBPnn39+bNiwISZNmhRdunSJ8ePHb8rceuutccwxx8Shhx4a55xzTvTq1SveeeedmDt3brzxxhvxwgsvbHPWBQsWxKBBg6Kqqir5B8xMmTIldt555zjjjDOS8gCfaann48knnxx//vOfY/z48fHMM8/EM888s+nvdt999zjxxBMT3jtAzlrq+XjeeefFHXfcERdeeGG8/PLL0aNHj/j1r38dy5Yti3/7t39LfwfR7CnGGbrtttu2+vioUaNi1KhRsWLFipg8eXI88cQT0bt377jvvvti2rRpUVNTs8Vzzj777GjVqlVMmjQp3n333TjqqKPilltuiT333HNTpnfv3rFw4cKYMGFC3HPPPbF69ero1q1bHHHEEXHFFVeU9G17//33Y+bMmTFkyJDo2LFjSdcGWr6Wej5+9gnkddddt8XfDRw4UDEGPldLPR/btWsXs2fPjvHjx8ddd90Vf/nLX+Lwww+PmTNnbvP7m2mZCsX//JoHAAAAyIzvMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKxVpAYLhUJDzgGQpCn+6nXnI9AUOB8Bti7lfHRjDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsVZR7AAAAgKZot912S8o99thjSbnevXsn733EEUck5ZYsWZK8JtvmxhgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsVZR7AABoqfbcc8+k3K677pq85jnnnJOU69u3b/Kal156aVJu7ty5Sbna2trkvQEaW+fOnZOzM2fOTModddRRSbkbbrghee/XXnstOUv9uTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWSsUi8ViUrBQaOhZAD5X4pHVqJyP+enQoUNS7qWXXkrK7bnnnvUZp9H89Kc/Tco99thjyWvOmzevruPwd5yP5K5z585JuZkzZyavefTRRyflbrjhhqTcP//zPyfv/emnnyZn2b6U89GNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFkrFIvFYlKwUGjoWQA+V+KR1aicj+XRunXrpNxZZ52VlJswYULy3q1apX1duXv37slrtiTr169Pzk6cODEpd/nll9d1nGw4H8nd//pf/yspN3LkyOQ177777qTceeedl5TbuHFj8t6UTsr56MYYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArFWUewCav5122ikpV11dnbxm+/btk3I//OEPk9dcsWJFUu6uu+5KXjNV6pqvvfZa8pq1tbV1HQdahFmzZiXlTjzxxAaepHGtWbMmKde5c+cGnmTb2rZtm5z9whe+0ICTAM3d3XffnZwdMWJEUu75559PXvOyyy5Lym3cuDF5TZomN8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4VisVhMChYKDT0LTcyQIUOScpdeemlSrn///sl7J35Ytjj/9E//lJy97bbbGnCSpqspfmw4H8tj+fLlSbm99967gSfZtoULFyblfvvb3yaveffddyflduQ8+eEPf5icLbXJkycn5c4///wGnqT5cz7SnIwbNy4pd9111yWv+cILLyTlTjnllOQ1V6xYkZyl6Uo5H90YAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkLWKcg9AafTp0ycpd/755yev+c1vfjMp17Zt26Tc6tWrk/des2ZNcjbVzjvvnJTr3r17yfdOdfHFFydn77///qTcunXr6jgNNG2/+MUvknKnn356Uq6iIv0/iY8++mhS7rrrrkvK/fWvf03ee/DgwUm5c889N3nNcvrkk0/KPQJQQv369UvKXXrppUm59evXJ++d+nnuihUrktckH26MAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYqyj0A27frrrsm5f7lX/4lKfe1r32tPuNs1TvvvJOU++pXv5q85uLFi+s6zjbttttuSbkrr7wyKXfBBRfUZ5ytWr58eXJ2w4YNJd8fmpNrrrmmpLnmYujQoUm5tm3bNuwgJTJjxoxyjwB8jtTPRyMi7rzzzqRcp06dknLnn39+8t7z5s1LzsLfc2MMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1irKPUCOOnbsmJy9++67k3Jf+9rX6jpOvV155ZVJucWLFzfwJNv3ySefJOX69OnTwJNs2zPPPJOcXb9+fQNOAjSmE088MTn77W9/uwEnaXwVFT4Vgabul7/8ZXL24IMPTsrdddddSbnJkycn7w314cYYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArBWKxWIxKVgoNPQszd6uu+6alLvnnnuS1/z6179ex2nq7/TTT0/KzZw5Myn36aef1mecejv88MOTcr///e9LvveKFSuScn379k1e86233qrrOM1a4pHVqJyPbEuvXr2Sck899VTymnvvvXddx2k03/3ud5OzU6ZMScpt3LixruNkw/nIjho6dGhS7pe//GXymmvWrEnKVVZWJuXefvvt5L1hW1LORzfGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGsV5R6gJRkyZEhS7utf/3oDT7Jt1157bXL2scceS8p9+umndR2nUR188MFl2/vpp59Oyr311lsNPAlQChUVaf/5vPXWW5Nye++9d33GaTTvvfdeUm727NnJa27cuLGu4wDbsMceeyTl7rzzzqRc586dk/c+66yzknJvv/128pql9uUvfzk5u99++5V078WLFzdIlvpzYwwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWKso9QFPXs2fP5OzkyZMbbpDPMWvWrKRcVVVV8pqffPJJXcdpNLvuumtydsyYMQ04yfaV82MDKL0+ffok5QYPHtzAkzSuSy+9NCm3fPnyBp4E2J7bbrstKbfbbrsl5e66667kvZ988snkbIovf/nLydlf//rXSbkvfvGLyWtWVJS2Lq1duzY5+5WvfCUpt3Tp0roNw2bcGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJC1inIP0NSNHTs2Odu+ffuS779s2bKk3Lhx45Jyn3zySX3GaXKGDBmSnD3yyCNLuvd1112XnH3mmWdKujeQbtddd03KVVdXJ695/vnn13Ga5u3Xv/51uUeAbA0cODA5e+qppybl1q5dm5S77LLLkvf+9NNPk3I/+MEPknI///nPk/du06ZNUu6VV15JXvP2229Pyn35y19Oyp199tnJe5977rlJuUsvvTR5TbbNjTEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADIWkW5ByiXPfbYIyl33nnnNfAk2zd69Oik3EsvvdTAkzSuDh06JOXGjh3bwJNs28yZM5Ozn3zySQNOAnlq3bp1Um7KlClJuSFDhtRnnCbn/fffT84+8MADSbmPP/64ruMA9XTLLbckZ1PPx/HjxyflVq5cmbz3L37xi6TcqFGjknJ/+ctfkvceOnRoUu73v/998pqp+++6665JucrKyuS927Rpk5yl/twYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkLWKcg9QLh9++GFSbsGCBclrfvnLX07KTZw4MXnNOXPmJGebul122SU5O3v27KRcnz59ktd86623knLHHXdcUm7JkiXJewOld9111yXlhgwZ0sCTNE0PPPBAcva8885rwEmA7TnssMOScgceeGDymqtXr07KzZw5Mym3I+foD37wg6TcsmXLknLf/OY3k/eeP39+crbULrzwwqRcjx49GngS6sqNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMhaRbkHKJcPP/wwKXfsscc28CTN30knnZSUu/rqq5PX/MpXvpKUq62tTV7z1VdfTcotWbIkeU0gzR577JGUu/nmm5PX/MY3vlHXcZqcjz76KDn70EMPJeUuvPDCuo4DNKIuXbok5dq0aZO85v3335+UW7lyZVLu0ksvTd479XOzc845Jyk3f/785L0bwoknnpiU+/73v5+Ue/3115P3vvvuu5Oz1J8bYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALJWUe4BaLo6deqUlKuurk7KHXnkkcl7F4vFpNxdd92VvObVV1+dnAU+X48ePZKzY8eOTcqdccYZdR2nSSoUCkm53/3ud8lr/s//+T+Tchs3bkxeEyifIUOGlHzNhx56KCm3++67J+X69u2bvPfUqVOTcv/n//yf5DVL7bTTTkvO/vznP0/Kde7cOSl33nnnJe/9pz/9KTlL/bkxBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGsV5R6AxtWlS5fk7COPPJKUO/roo5NytbW1yXv/7ne/S8pdffXVyWsuXbo0OQt8vuHDhydnf/jDHzbgJE1XsVhMyp1wwgnJaw4aNCgpN2fOnOQ1Z8yYkZS74447knIbN25M3htyt2TJkpKvmXo+T5o0KSn3ySefJO/9zjvvJOU6d+6clBs5cmTy3qmfk5555pnJa65YsSIp981vfjMp9/jjjyfvTeNyYwwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyVigWi8WkYKHQ0LNQD127dk3KTZs2LXnNY489tq7jbNXixYuTs4ccckhJ96blSDyyGlWu52N1dXVy9oorrmi4QWg0GzduTMrNmjUrec3f/OY3SbkZM2Ykr7lu3brkbEvifGyeOnbsmJT7j//4j+Q199lnn6Tc0qVLk3KpM0ZE7LbbbsnZUvv444+TcrfeemvymjfffHNSLvV9SXmknI9ujAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMhaoVgsFpOChUJDz8JWdO3aNSl38cUXJ+V+/OMf12Oa+jn++OOTszU1NQ03CM1a4pHVqHI9H1977bXk7L777tuAk5CDSy65JDl74403NuAkTZfzsWX74he/mJz9l3/5l6TcWWedVddxtunPf/5zUm7BggVJublz5ybv/Zvf/CYp9/rrryevScuQcj66MQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZKxSLxWJSsFBo6FnYimnTpiXlvvGNbzTwJPU3a9as5Oxpp53WgJPQnCUeWY0q1/Px9NNPT85eeeWVSblDDjkkec2NGzcm5YYPH56Ue/HFF5P37tu3b1Lu6KOPTl6znL75zW8m5b7whS8k5WbOnJm89y677JKUO+OMM5LXXL16dXK2JXE+AmxdyvnoxhgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsFYrFYjEpWCg09CzZGD16dHL2pptuSsq1bdu2ruPU2+23356Uu+yyy5LXfO+99+o6Di1c4pHVqJyPQFPgfATYupTz0Y0xAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWaso9wA5OuOMM5Kzbdu2bcBJtu/OO+9Myl1++eVJuffee68+4wAAADQIN8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4VisVhMChYKDT1LNvbff//k7JNPPpmU+/DDD5NyEyZMSN572rRpSbnEDyEoiab48eZ8BJoC5yPA1qWcj26MAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyFqhWCwWk4KFQkPPAvC5Eo+sRuV8BJoC5yPA1qWcj26MAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJC1QrFYLJZ7CAAAACgXN8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGFMnS5cujUKhENdff33J1qypqYlCoRA1NTUlWxOgsTkfAbbO+UhTphhn5J577olCoRALFy4s9ygNomfPnlEoFLb654ADDij3eEAT1tLPx4iIqVOnxle+8pVo27ZtdO3aNUaPHh2rVq0q91hAE5fD+RgR8cADD0T//v2jffv20alTpxgwYEDMnj273GPRiCrKPQCUyqRJk+LDDz/c7LFly5bFZZddFieddFKZpgIov9tuuy0uuOCCOP744+OGG26IN954I37+85/HwoULY/78+dG2bdtyjwhQNtXV1XHllVfGsGHDYtSoUfHJJ5/EokWL4s033yz3aDQixZgWY+jQoVs8dtVVV0VExFlnndXI0wA0DR9//HFceumlcdxxx8Vvf/vbKBQKERExYMCAOO200+KXv/xl/Pf//t/LPCVAecybNy+uvPLKmDhxYowZM6bc41BGXkrNZj7++OO44oor4sgjj4yOHTtG+/bt49hjj405c+Zs8zk33nhj7LvvvtGuXbsYOHBgLFq0aIvM4sWLY9iwYdG5c+do27Zt9OnTJx599NHPneevf/1rLF68uM4v97v//vtjv/32iwEDBtTp+QCfaa7n46JFi2Lt2rUxcuTITaU4IuLUU0+NDh06xNSpUz93L4Dtaa7nY8TfXnG4xx57xEUXXRTFYnGLVx+SD8WYzbz//vtxxx13RGVlZVx77bVRXV0dK1eujMGDB8fzzz+/Rf5Xv/pV3HTTTXHhhRfGT37yk1i0aFF89atfjXfeeWdT5o9//GP069cvXnzxxfjxj38cEydOjPbt28fQoUPj4Ycf3u48CxYsiIMPPjhuueWWHX5b/vCHP8SLL74YZ5555g4/F+DvNdfzccOGDRER0a5duy3+rl27dvGHP/whamtrE94DAFvXXM/HiIgnn3wy+vbtGzfddFN07do1dtlll9hzzz3r9LknzVyRbNx9993FiCg+++yz28xs3LixuGHDhs0ee++994q777578Xvf+96mx1577bViRBTbtWtXfOONNzY9Pn/+/GJEFMeMGbPpseOPP7546KGHFtevX7/psdra2uKAAQOKBxxwwKbH5syZU4yI4pw5c7Z4rKqqaoff3ksuuaQYEcU//elPO/xcIC8t+XxcuXJlsVAoFEePHr3Z44sXLy5GRDEiiqtWrdruGkC+WvL5uGbNmmJEFLt06VLs0KFD8Wc/+1nxgQceKJ588snFiCjefvvt230+LYsbYzbTunXr2GmnnSIiora2NtasWRMbN26MPn36xHPPPbdFfujQobH33ntv+t9HHXVUHH300TFr1qyIiFizZk3Mnj07RowYER988EGsWrUqVq1aFatXr47BgwfHK6+8st0fbFBZWRnFYjGqq6t36O2ora2NqVOnxhFHHBEHH3zwDj0XYGua6/n4hS98IUaMGBH33ntvTJw4Mf785z/H008/HSNHjow2bdpERMRHH320o+8OgE2a6/n42cumV69eHXfccUeMGzcuRowYETNnzozevXtv+lk15EExZgv33ntvHHbYYdG2bdvo0qVLdO3aNWbOnBnr1q3bIru1X4N04IEHxtKlSyMi4tVXX41isRiXX355dO3adbM/VVVVERHx7rvvlvxteOqpp+LNN9/0Q7eAkmqu5+PkyZPjH//xH2PcuHHxD//wD3HcccfFoYceGqeddlpERHTo0KEk+wD5ao7n42ffYtKmTZsYNmzYpsdbtWoVI0eOjDfeeCNef/31eu9D8+CnUrOZ++67L0aNGhVDhw6NH/3oR9GtW7do3bp1XHPNNbFkyZIdXu+z71sbN25cDB48eKuZ/fffv14zb82UKVOiVatW8a1vfavkawN5as7nY8eOHeM3v/lNvP7667F06dLYd999Y999940BAwZE165do1OnTiXZB8hTcz0fP/uhXp06dYrWrVtv9nfdunWLiIj33nsvevToUe+9aPoUYzYzffr06NWrV8yYMWOzn1762Vfn/t4rr7yyxWMvv/xy9OzZMyIievXqFRF/+0rcCSecUPqBt2LDhg3x0EMPRWVlZey1116NsifQ8rWE87FHjx6bPsFbu3Zt/P73v48zzjijUfYGWq7mej62atUqDj/88Hj22Wfj448/3vRy8IiIt956KyIiunbt2mD707R4KTWb+eyrZcVicdNj8+fPj7lz5241/8gjj2z2PR4LFiyI+fPnxymnnBIRf/tqW2VlZUyePDnefvvtLZ6/cuXK7c5Tl1/XNGvWrFi7dq2XUQMl1RLOx//sJz/5SWzcuNHv7QTqrTmfjyNHjoxPP/007r333k2PrV+/PqZMmRK9e/d2yZIRN8YZuuuuu+Lxxx/f4vGLLrooTj311JgxY0acfvrpMWTIkHjttdfi9ttvj969e2/197rtv//+ccwxx8T5558fGzZsiEmTJkWXLl1i/PjxmzK33nprHHPMMXHooYfGOeecE7169Yp33nkn5s6dG2+88Ua88MIL25x1wYIFMWjQoKiqqkr+AVxTpkyJnXfe2S0IsMNa6vn4P/7H/4hFixbF0UcfHRUVFfHII4/Ev//7v8dVV10Vffv2TX8HAdlqqefjeeedF3fccUdceOGF8fLLL0ePHj3i17/+dSxbtiz+7d/+Lf0dRLOnGGfotttu2+rjo0aNilGjRsWKFSti8uTJ8cQTT0Tv3r3jvvvui2nTpkVNTc0Wzzn77LOjVatWMWnSpHj33XfjqKOOiltuuSX23HPPTZnevXvHwoULY8KECXHPPffE6tWro1u3bnHEEUfEFVdcUdK37f3334+ZM2fGkCFDomPHjiVdG2j5Wur5eOihh8bDDz8cjz76aHz66adx2GGHxYMPPhjDhw8v2R5Ay9ZSz8d27drF7NmzY/z48XHXXXfFX/7ylzj88MNj5syZ2/z+ZlqmQvE/v+YBAAAAMuN7jAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFmrSA0WCoWGnAMgSbFYLPcIW3A+Ak2B8xFg61LORzfGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyVlHuAQAAoNQGDRqUnJ0zZ04DTsLWpL7PO3TokLxm37596zoOuDEGAAAgb4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWaso9wAAAFBqO+20U7lHyNIVV1yRlDvuuONKvvepp56alPvf//t/l3xvmj83xgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGStUCwWi0nBQqGhZwH4XIlHVqNyPrItlZWVSbmqqqqSr1lTU5O85oQJE0q+Jo3P+UhDOfHEE5Ozjz32WFKuVavS388tXLgwKXfUUUeVfG+atpTz0Y0xAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWSsUi8ViUrBQaOhZtmmvvfZKzj7zzDNJuZUrVybl+vTpk7z3448/npQ7++yzk9dcvXp1chZykHhkNapyno+UR2VlZVJuzpw5DTtIiQwaNCgpV1NT07CDUC/OR3ZUz549k3KPPfZY8po77bRTHafZuv322y85e+aZZyblpk6dWtdxaKZSzkc3xgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrFeUeIEWHDh2Ss507d07K9ejRIylXLBaT9z755JOTci+99FLymjNnzkzKvfjii0m5xx57LHnvF154ITkL0NxVVlYmZ+fMmVPSvQuFQknXA0jx3e9+Nyl30EEHNfAk27Zq1ark7OLFixtwElo6N8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkrVAsFotJwUKhoWcpia985StJuS5duiTlfvCDHyTvvdtuuyXljjvuuOQ1y+nRRx9Nyi1dujQp17t373pMU3+pH8PvvvtuUm7SpEnJe//+979PzrJ9iUdWo2ou52OuKisrk3JVVVUlX3PQoEFJuZqamuS9YVucj3xm3333Tco9/fTTSbl99tmnPuNs1cqVK5Nyt99+e/KaO3KOk5eU89GNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMhaRbkHKLXnnnuupOv99re/Tc62adMmKXfQQQclrzl8+PCk3L777pu8ZqpCoZCUO+2005Jy++23X33GqbfUt6dYLCblUt/uiIg+ffok5V599dXkNYE0lZWVJc1FREyYMCEpV1NTk7wmQKl873vfS8rts88+DTzJtr388stJuaqqqpLvPWDAgORsOd9Hn3zySVLu4YcfbuBJ8uDGGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwVisViMSlYKDT0LDRTHTt2TMrtvPPODTzJ9nXr1i0p9/zzz5d878MPPzwpt2jRopLv3dIkHlmNyvnYtM2ZMycpV1lZmbymf3OaIudjy3bqqacmZ6dPn56U22mnneo6Tr2deeaZSblPP/00ec3LL788KdejR4/kNXfdddfkbKnV1tYm5Xbkc9c+ffrUcZrmLeV8dGMMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1irKPQDN37p168o9QpIOHTok5QqFQsn3btXK16CgXCorK8s9AkC97bbbbsnZnXbaqQEn2b7XXnstKfed73wnKde/f//kvXfdddfkbHOQ+vnjEUcckbzm6NGjk3J33nln8pothc/WAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYqyj0ANJYf/OAHSblisVjyvWtra0u+JuSusrKy3CN8rtQZd+RtqaqqSsoNGjQoec2amprkLFAe3//+98s9QpL99tuvpDk+X6FQSM7uueeeDThJ8+bGGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKxVlHsAaCw9e/Ys6XrPPfdccnbZsmUl3Rsor+rq6qRcVVVVww5Sor1ramoabhCgJHr06FHuEaBFc2MMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1irKPQDUxyGHHJKcPeOMM5Jya9asScqNHz8+ee8PPvggOQukqampKdveVVVVZds79e2urKxMXrO6urqkOSDd6NGjk3K77757A0+Sj/Xr1ydnFyxYkJSbP39+Uu5HP/pR8t40LjfGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGsV5R4A6uM3v/lNyddcvnx5Uq6mpqbkewOlN2jQoKRcVVVV8ppPPfVUUi71nGiI86RYLCZnBw4cWPL9gTQ//elPk3Jt27Zt4ElKo1AoJOVSz6iPPvooee9nnnkmKTd16tTkNQ855JCk3Pjx45NyO3I2p9qRNd99992S799SuDEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4VisVhMChYKDT0LbNKuXbuk3NKlS5PX7NatW1Lu5z//eVLu4osvTt6b0kk8shqV85GmqCH+v+JjvWlzPjZPb731VlJujz32aOBJmqZJkyYlZz/88MOk3He/+93kNffee+/kbKnV1tYm5f70pz8lr3nYYYfVdZxmLeV8dGMMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAslYoFovFpGCh0NCzwCZjxoxJyv3sZz9LXvODDz5Iyh1xxBFJuaVLlybvTekkHlmNyvlIU1RdXZ2craqqSsr5WG/anI/N01tvvZWU22OPPRp4Epqa1M9dO3bs2MCTNH8p56MbYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALJWUe4ByEeXLl2SsxdeeGHJ91+8eHFSbunSpSXfGwBga95///2k3B577NHAk1AfhUIhKbd27drkNe+///46TkNduDEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAgaxXlHoB8HHnkkcnZnj17lnz/hx56qORrAgDUx9ChQ5Ny48ePT15z1KhRdRuGLSxfvjwpd8011yTlnn766eS9//jHPyZnqT83xgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrFeUeAABoHqqrq0uaAyIWL16clPv3f//35DW/853vJOUKhULymi3J8uXLk7ODBw9OyqX+O9J0uTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAgaxXlHgC2plAolHzNv/zlLyVfEyAnAwcOLPcIkK2pU6cmZ48++uik3A9/+MOkXEN8XpaqWCwmZ5cvX56UGzx4cPKaL730UnKW5s2NMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMhaoVgsFpOChUJDz0ILd9JJJyVnZ82aVfL9KyoqknLdunVLyr377rv1GYc6SjyyGpXzkeau1P+/GjRoUHK2pqampHvnzPnIjjr33HOTcpdffnnymnvvvXdS7vXXX0/K/fSnP03e+84770zOkpeU89GNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFkrFIvFYlKwUGjoWWjhTjrppOTsrFmzSr7/k08+mZTbuHFjUm7IkCH1GYc6SjyyGpXzkeauuro6KVdVVVXyvQcNGpSUq6mpKfneLY3zEWDrUs5HN8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkraLcA0Bj6dy5c1LuqquuauBJAJqW6urqpNzAgQOTck899VTy3jU1NclZAGgobowBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1grFYrGYFCwUGnoWWrgDDzwwOTt69OikXJ8+fZLXvPLKK5NyTz31VPKaNL7EI6tROR+BpsD5CLB1KeejG2MAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyVigWi8WkYKHQ0LMAfK7EI6tROR+BpsD5CLB1KeejG2MAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZK1QLBaL5R4CAAAAysWNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnG1MnSpUujUCjE9ddfX7I1a2pqolAoRE1NTcnWBGhszkeArXM+0pQpxhm55557olAoxMKFC8s9SoN58803Y8SIEdGpU6fYdddd4+tf/3r8+c9/LvdYQBPX0s/Hl156KcaMGRMDBgyItm3bRqFQiKVLl5Z7LKAZaOnnY8+ePaNQKGz1zwEHHFDu8WhEFeUeAErlww8/jEGDBsW6devi0ksvjTZt2sSNN94YAwcOjOeffz66dOlS7hEBymLu3Llx0003Re/evePggw+O559/vtwjATQJkyZNig8//HCzx5YtWxaXXXZZnHTSSWWainJQjGkxfvGLX8Qrr7wSCxYsiL59+0ZExCmnnBJf+tKXYuLEifGv//qvZZ4QoDy+9rWvxdq1a2OXXXaJ66+/XjEG+H+GDh26xWNXXXVVREScddZZjTwN5eSl1Gzm448/jiuuuCKOPPLI6NixY7Rv3z6OPfbYmDNnzjafc+ONN8a+++4b7dq1i4EDB8aiRYu2yCxevDiGDRsWnTt3jrZt20afPn3i0Ucf/dx5/vrXv8bixYtj1apVn5udPn169O3bd1Mpjoj44he/GMcff3w8+OCDn/t8gO1pzudj586dY5dddvncHEBdNOfzcWvuv//+2G+//WLAgAF1ej7Nk2LMZt5///244447orKyMq699tqorq6OlStXxuDBg7d6w/CrX/0qbrrpprjwwgvjJz/5SSxatCi++tWvxjvvvLMp88c//jH69esXL774Yvz4xz+OiRMnRvv27WPo0KHx8MMPb3eeBQsWxMEHHxy33HLLdnO1tbXxf//v/40+ffps8XdHHXVULFmyJD744IO0dwLAVjTX8xGgobWk8/EPf/hDvPjii3HmmWfu8HNp3ryUms3stttusXTp0thpp502PXbOOefEF7/4xbj55pvjzjvv3Cz/6quvxiuvvBJ77713REScfPLJcfTRR8e1114bN9xwQ0REXHTRRdGjR4949tlnY+edd46IiAsuuCCOOeaY+Od//uc4/fTT6z33mjVrYsOGDbHnnntu8XefPfbWW2/FQQcdVO+9gDw11/MRoKG1pPNxypQpEeFl1DlyY8xmWrduvelQq62tjTVr1sTGjRujT58+8dxzz22RHzp06KZDLeJvt7NHH310zJo1KyL+Vlhnz54dI0aMiA8++CBWrVoVq1atitWrV8fgwYPjlVdeiTfffHOb81RWVkaxWIzq6urtzv3RRx9FRGw6OP+ztm3bbpYBqIvmej4CNLSWcj7W1tbG1KlT44gjjoiDDz54h55L86cYs4V77703DjvssGjbtm106dIlunbtGjNnzox169Ztkd3aj7E/8MADN/0akFdffTWKxWJcfvnl0bVr183+VFVVRUTEu+++W++Z27VrFxERGzZs2OLv1q9fv1kGoK6a4/kI0Bhawvn41FNPxZtvvum2OFNeSs1m7rvvvhg1alQMHTo0fvSjH0W3bt2idevWcc0118SSJUt2eL3a2tqIiBg3blwMHjx4q5n999+/XjNH/O0Hy+y8887x9ttvb/F3nz2211571XsfIF/N9XwEaGgt5XycMmVKtGrVKr71rW+VfG2aPsWYzUyfPj169eoVM2bMiEKhsOnxz7469/deeeWVLR57+eWXo2fPnhER0atXr4iIaNOmTZxwwgmlH/j/adWqVRx66KFb/eXz8+fPj169evmJrEC9NNfzEaChtYTzccOGDfHQQw9FZWWly5RMeSk1m2ndunVERBSLxU2PzZ8/P+bOnbvV/COPPLLZ93gsWLAg5s+fH6ecckpERHTr1i0qKytj8uTJW73NXbly5Xbn2ZEftz9s2LB49tlnNyvHL730UsyePTuGDx/+uc8H2J7mfD4CNKSWcD7OmjUr1q5d62XUGXNjnKG77rorHn/88S0ev+iii+LUU0+NGTNmxOmnnx5DhgyJ1157LW6//fbo3bt3fPjhh1s8Z//9949jjjkmzj///NiwYUNMmjQpunTpEuPHj9+UufXWW+OYY46JQw89NM4555zo1atXvPPOOzF37tx444034oUXXtjmrAsWLIhBgwZFVVXV5/4AhQsuuCB++ctfxpAhQ2LcuHHRpk2buOGGG2L33XePSy65JP0dBGSrpZ6P69ati5tvvjkiIn73u99FRMQtt9wSnTp1ik6dOsU//dM/pbx7gIy11PPxM1OmTImdd945zjjjjKQ8LY9inKHbbrttq4+PGjUqRo0aFStWrIjJkyfHE088Eb1794777rsvpk2bFjU1NVs85+yzz45WrVrFpEmT4t13342jjjoqbrnlls1+bVLv3r1j4cKFMWHChLjnnnti9erV0a1btzjiiCPiiiuuKNnbtcsuu0RNTU2MGTMmrrrqqqitrY3Kysq48cYbo2vXriXbB2i5Wur5+N5778Xll1++2WMTJ06MiIh9991XMQY+V0s9HyP+9nuYZ86cGUOGDImOHTuWdG2aj0LxP7/mAQAAADLje4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrFanBQqHQkHMAJGmKv3rd+Qg0FU3tjHQ+Ak1BytnoxhgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAgaxXlHoDmr3v37km5YcOGJa/Zv3//uo5Tb3Pnzk3KvfnmmyVfc/ny5clrAi1LZWVlUq6qqqrka06YMCF5zerq6uQsADQXbowBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADIWkW5B6A0unfvnpS7+OKLk9ccPnx4SfduLlLf7oYwbdq05Owll1ySlFu+fHldxwEaUVVVVVKusrKyYQcBgAy5MQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZqyj3AGzfiBEjknLXX399Uq579+71GafJmTZtWsnX7NevX1KuId6Xw4cPT87us88+SbkBAwbUdRygET311FNJucrKyoYdBAAy5MYYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArFWUewC2b9iwYUm57t27N/Ak9Tdt2rTk7A033JCUmzdvXl3HqbcdeZ9PnDgxKTd8+PDkNfv375+Ue/DBB5NyI0aMSN4bACiN1P/+duvWrYEnyceSJUuSs4899lgDTkJT4sYYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZK2i3AOwfcuXLy/3CCUzffr05Oy8efMacJLS2JF/m9S3ffjw4XUdBwD4T770pS8lZy+44IKk3GmnnVbXcbapa9euSbk2bdqUfO9yatUq7X6utra25HuvX78+Oftf/+t/Tco9//zzdZyGpsKNMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFmrKPcAORoxYkRyduzYsSXde/ny5cnZG2+8MSk3d+7cuo6TjdT30Y78+3Tv3r2u4wBspqamptwjQMnNnj07Obtu3bqkXOfOnZNybdu2Td47V8VisWx778i/T0WFupQLN8YAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkraLcA7QkY8aMScrdcMMNJd97+fLlSbkRI0Ykrzlv3ry6jsPfSf33mTZtWvKaY8eOres4QBNUVVVVtr1ramrKtjc0lH/8x39Mzq5cuTIpt9tuuyXlKirSP8Xef//9k3Lf+973ktdsDgqFQlJu4MCByWu2bt26ruOAG2MAAADyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQtYpyD9DUde/ePTk7ZsyYku8/d+7cpNzIkSOTcsuXL6/PODSwHfl4S9WvX7+Srwk0DxMmTCj3CFA2CxcuLPmay5YtK/maqXNOnTq15Hs3B+vWrUvOdujQoeT7jx49OinXEB9vNC43xgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGStotwDNHUTJ05Mznbv3r3k+48dOzYpt3z58pLvTcswb968co8AANAs/cM//ENJ19tnn32Ssx06dEjKnXzyyclrPv7440m5xYsXJ6/ZUrgxBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGsV5R6gXEaMGJGUGz58eMn3njZtWnJ23rx5Jd+fxtevX7+kXEN8vAHlVV1dXba9a2pqyrY30PS1bt06KbfHHnuUfO/KysqkXNu2bUu+94445JBDknL33ntvUm7gwIHJe3fv3j05m2rixIlJudSPjZbEjTEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADIWkW5ByiXiy++uGx733DDDWXbm/Lo0aNHuUcAMlRTU1PuEYAyOPfcc5Ny/fr1S8p95zvfqc84W1UoFJJyxWKx5HvviD322CMp9+1vf7vke6e+7atXr05e88orr6zrOC2eG2MAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyVlHuAUptxIgRSbn+/fuXfO9p06Yl5ebNm1fyvWna9t5777LtPX369LLtDQA0vpNPPjkp9/Wvf72BJ+Hv3XfffcnZBQsWJOVuvfXWuo7Df+LGGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGStotwDlNrFF19ctr2XL19etr1pfN27d0/OjhkzpuT7p368zZ07t+R7A+kGDhxY7hGAzHzjG98o9wifq7KyMin3xBNPJK/Zpk2bOk6zbcuWLUvKnXDCCUm5JUuW1GccGpAbYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALJWUe4BSq1///5l23v+/Pll25vGN3HixORs9+7dS77/jTfemJRbvnx5yfcG0lVWVpZ7BIAmp6amJim3fv365DUrKkpfbT766KOk3IYNG0q+N43LjTEAAABZU4wBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZqyj3AKU2d+7cpFz//v0beBKaqzFjxiTlhg8fXvK9Uz9+IyKmT59e8v0BAPj/HXTQQUm5Aw44ICn3xhtv1GccGpAbYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJC1inIPUGqTJk1KyvXv37/ke1988cVJuQcffLDke/P5xowZk5S74YYbSr738uXLk3Jjx44t+ZpAyzJhwoRyjwDA3/nSl76UlJszZ04DT0JduTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAgaxXlHqDUHnzwwaTcsGHDknLDhw9P3rt///5Juddffz15zREjRiTl5s2bl7xmc9CvX7+k3I78+4wdO7au42zV8uXLk7O5/jtCS1VZWVnuEQBoQs4888yk3M0339zAk1BXbowBAADImmIMAABA1hRjAAAAsqYYAwAAkDXFGAAAgKwpxgAAAGRNMQYAACBrijEAAABZU4wBAADImmIMAABA1irKPUC5jBgxIik3ceLE5DXHjh2blOvevXvymnPnzk3KLV++PCk3b9685L1Lbfjw4WXbOyL9fTRu3Lik3IMPPlifcYBmrKqqqtwjAGThzjvvTM5edNFFDTgJLZ0bYwAAALKmGAMAAJA1xRgAAICsKcYAAABkTTEGAAAga4oxAAAAWVOMAQAAyJpiDAAAQNYUYwAAALJWKBaLxaRgodDQszR7/fr1S8oNHz48ec2xY8fWdZxmbfny5Um5adOmJa85adKkku5NeSQeWY3K+Zifcn4cTpgwITlbXV3dcIPQJDW1M9L5SH316tUrObtgwYKk3G677VbXceq9d//+/Uu+N58v5Wx0YwwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWCsVisZgULBQaeha2onv37km5/v37N/Ak9ff6668nZ+fNm9eAk9CcJR5Zjcr5mJ/q6urkbFVVVVKupqYmKTdo0KDkvclPUzsjnY80pquvvjop99/+239LXnPJkiVJueuuuy4p99hjjyXvTemknI1ujAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWCsVisZgULBQaehaAz5V4ZDUq5yPQVDS1M9L5CDQFKWejG2MAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFkrFIvFYrmHAAAAgHJxYwwAAEDWFGMAAACyphgDAACQNcUYAACArCnGAAAAZE0xBgAAIGuKMQAAAFlTjAEAAMiaYgwAAEDW/j+q0P9r4a9DIAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def show_images(examples):\n",
        "  random_indices = np.random.choice(examples.shape[0], 9, replace=False)\n",
        "\n",
        "  # rescale images (-1, +1) -> (0, 1)\n",
        "  examples = 0.5 * examples + 0.5\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i, index in enumerate(random_indices, 1):\n",
        "      plt.subplot(3, 3, i)\n",
        "      plt.imshow(x_train[index], cmap='gray')\n",
        "      plt.title(f\"Label: {labels_train[index]}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "show_images(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KoOFJ_8lKCF"
      },
      "source": [
        "# Evaluation metrics for the generated images\n",
        "\n",
        "Possible metrics:\n",
        "\n",
        "* inception score\n",
        "    * [medium article](https://medium.com/octavian-ai/a-simple-explanation-of-the-inception-score-372dff6a8c7a)\n",
        "    * [short code introduction](https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/)\n",
        "* parzen window estimation\n",
        "* conditional inception scores\n",
        "    * [Evaluation Metrics for Conditional Image Generation](https://arxiv.org/abs/2004.12361)\n",
        "* Frechet inception distance\n",
        "* kernel inception distance\n",
        "    * [KID code and GAN tips and trics](https://keras.io/examples/generative/gan_ada/#dataefficient-gans-with-adaptive-discriminator-augmentation)\n",
        "\n",
        "## Conditional inception scores and inception score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Vx5nWaBolKCG"
      },
      "outputs": [],
      "source": [
        "def kl_divergence(a, b):\n",
        "   '''Kullback-Leibler divergence\n",
        "   Smaller value means more similar distributions'''\n",
        "   a, b = np.atleast_2d(np.asarray(a)), np.atleast_2d(np.asarray(b))\n",
        "   eps = 1e-16\n",
        "   Dkls = a * np.log((a + eps) / (b + eps))\n",
        "   return Dkls.sum(axis=1)\n",
        "\n",
        "class InceptionScore(keras.metrics.Metric):\n",
        "    '''Inception score\n",
        "    IS = exp( Ex{ Dkl( pG_yx || pG_y ) } )'''\n",
        "\n",
        "    def __init__(self, name='inception_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mean_tracker = keras.metrics.Mean()\n",
        "\n",
        "    def update_state(self, y_hat):\n",
        "        IS = self._inception_score(y_hat)\n",
        "        self.mean_tracker.update_state(IS)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mean_tracker.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mean_tracker.reset_state()\n",
        "\n",
        "    def _inception_score(self, y_hat):\n",
        "        p_y = np.expand_dims(np.mean(y_hat, axis=0), 0)\n",
        "        # kl divergence for each image\n",
        "        Dkls = kl_divergence(y_hat, p_y)\n",
        "        return np.exp(Dkls.mean())\n",
        "\n",
        "class WithinClassInceptionScore(keras.metrics.Metric):\n",
        "    '''Within-class inception score\n",
        "    Measures the quality and diversity for each of the classes.\n",
        "    High WCIS indicates a wide coverage of real classes within the\n",
        "    conditioned classes, which is an undesired property.\n",
        "    wcis = exp( Ec{ Dkl( pG_yx || pG_yc ) } )'''\n",
        "\n",
        "    def __init__(self, name='within_class_inception_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mean_tracker = keras.metrics.Mean()\n",
        "\n",
        "    def update_state(self, y_hat, gen_labels):\n",
        "        wcis = self._wcis(y_hat, gen_labels)\n",
        "        self.mean_tracker.update_state(wcis)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mean_tracker.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mean_tracker.reset_state()\n",
        "\n",
        "    def _wcis(self, y_hat, labels):\n",
        "        classes = np.unique(labels)\n",
        "        Dkl = np.ndarray(len(classes))\n",
        "\n",
        "        I = np.ndarray(len(classes))\n",
        "        for i, cond in enumerate(classes):\n",
        "            # mean of pG_yx with the given condition, as in BCIS\n",
        "            pG_yc = np.expand_dims(np.mean(y_hat[labels == cond], axis=0), 0)\n",
        "            # x is sampled from the given class\n",
        "            pG_yx = y_hat[labels == cond]\n",
        "            # kl divergence for each sample within the class\n",
        "            Dkl = kl_divergence(pG_yx, pG_yc)\n",
        "            I[i] = Dkl.mean(axis=0)\n",
        "        return np.exp(I.mean())\n",
        "\n",
        "class BetweenClassInceptionScore(keras.metrics.Metric):\n",
        "    '''Between-class inception score\n",
        "    Measures how close the representation of classes is to real data.\n",
        "    Higher BCIS is better, it indicates the distinct class representation\n",
        "    of the conditioned classes and a wide coverage across the conditional\n",
        "    classes, which is desired.\n",
        "    bcis = exp( Ec{ Dkl( pG_yc || pG_y ) } )'''\n",
        "\n",
        "    def __init__(self, name='between_class_inception_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mean_tracker = keras.metrics.Mean()\n",
        "\n",
        "    def update_state(self, y_hat, gen_labels):\n",
        "        bcis = self._bcis(y_hat, gen_labels)\n",
        "        self.mean_tracker.update_state(bcis)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mean_tracker.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mean_tracker.reset_state()\n",
        "\n",
        "    def _bcis(self, y_hat, labels):\n",
        "        pG_y = np.expand_dims(np.mean(y_hat, axis=0), 0) # mean for all generated samples of pG_yx\n",
        "\n",
        "        classes = np.unique(labels)\n",
        "        Dkl = np.ndarray(len(classes))\n",
        "        for i, cond in enumerate(classes):\n",
        "            # mean on classes of the pG_yx values\n",
        "            pG_yc = np.expand_dims(np.mean(y_hat[labels == cond], axis=0), 0)\n",
        "            Dkl[i] = kl_divergence(pG_yc, pG_y)[0]\n",
        "        return np.exp(Dkl.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK5webqllwq5"
      },
      "source": [
        "# Define Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kMKJKDuySO7H"
      },
      "outputs": [],
      "source": [
        "class CGAN(tf.keras.Model):\n",
        "  def __init__(self, config):\n",
        "    super(CGAN, self).__init__()\n",
        "\n",
        "    self.latent_dim = config['latent_dim']\n",
        "    self.n_classes = config['n_classes']\n",
        "\n",
        "    # create generator\n",
        "    self.generator = self.build_generator(\n",
        "      latent_dim=self.latent_dim, n_classes=self.n_classes, label_embedding=config['gen_label_embedding'],\n",
        "      label_hidden=config['gen_label_hidden'], input_hidden=config['gen_input_hidden'],\n",
        "      conv1_channels=config['gen_conv1_channels'], conv2_channels=config['gen_conv2_channels'])\n",
        "\n",
        "    # create discriminator\n",
        "    self.discriminator = self.build_discriminator(\n",
        "      n_classes=self.n_classes, label_embedding=config['disc_label_embedding'],\n",
        "      conv1_channels=config['disc_conv1_channels'], conv2_channels=config['disc_conv2_channels'],\n",
        "      dense_hidden=config['disc_dense_hidden'])\n",
        "\n",
        "    # classificator model used for validation\n",
        "    self.val_model = load_model(VAL_MODEL_PATH)\n",
        "\n",
        "    # add tracker\n",
        "    self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
        "    self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "    self.real_accuracy_tracker = keras.metrics.BinaryAccuracy(name=\"real_accuracy\")\n",
        "    self.fake_accuracy_tracker = keras.metrics.BinaryAccuracy(name=\"fake_accuracy\")\n",
        "    self.is_tracker = InceptionScore()\n",
        "    self.wcis_tracker = WithinClassInceptionScore()\n",
        "    self.bcis_tracker = BetweenClassInceptionScore()\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.gen_loss_tracker,\n",
        "            self.disc_loss_tracker,\n",
        "            self.real_accuracy_tracker,\n",
        "            self.fake_accuracy_tracker,\n",
        "            self.is_tracker,\n",
        "            self.wcis_tracker,\n",
        "            self.bcis_tracker,]\n",
        "\n",
        "  @property\n",
        "  def train_metrics(self):\n",
        "    return [self.gen_loss_tracker,\n",
        "            self.disc_loss_tracker,\n",
        "            self.real_accuracy_tracker,\n",
        "            self.fake_accuracy_tracker,]\n",
        "\n",
        "  @property\n",
        "  def val_metrics(self):\n",
        "    return [self.is_tracker,\n",
        "            self.wcis_tracker,\n",
        "            self.bcis_tracker,]\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    tf.config.run_functions_eagerly(True)\n",
        "\n",
        "    # set optimizers\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "\n",
        "    # set loss function\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    super(CGAN, self).compile()\n",
        "\n",
        "  def generate_latent_points(self, n_samples):\n",
        "    x_input = np.random.randn(self.latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, self.latent_dim)\n",
        "    x_labels = np.random.randint(0, self.n_classes, n_samples)\n",
        "    return [x_input, x_labels]\n",
        "\n",
        "  def generate_fake_samples(self, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input, x_labels = self.generate_latent_points(n_samples)\n",
        "\n",
        "    # predict outputs\n",
        "    imgs = self.generator([x_input, x_labels], training=False)\n",
        "\n",
        "    # create class labels\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    return [imgs, x_labels], y\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, data):\n",
        "    # Unpack the data\n",
        "    real_images, real_labels = data\n",
        "\n",
        "    # Get batch size\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    # Get randomly selected 'real' samples, with labels\n",
        "    x_real, y_real = [real_images, real_labels], np.ones((batch_size, 1))\n",
        "\n",
        "    # Update discriminator model weights\n",
        "    with tf.GradientTape() as tape:\n",
        "      real_predictions = self.discriminator(x_real)\n",
        "      d_loss_real = self.loss_fn(y_real, real_predictions)\n",
        "    grads = tape.gradient(d_loss_real, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    # Generate 'fake' examples, with labels\n",
        "    x_fake, y_fake = self.generate_fake_samples(batch_size)\n",
        "\n",
        "    # Update discriminator model weights\n",
        "    with tf.GradientTape() as tape:\n",
        "      fake_predictions = self.discriminator(x_fake)\n",
        "      d_loss_fake = self.loss_fn(y_fake, fake_predictions)\n",
        "    grads = tape.gradient(d_loss_fake, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    # Calculate loss\n",
        "    d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
        "\n",
        "    # Prepare points in latent space as input for the generator\n",
        "    x_gan = self.generate_latent_points(2 * batch_size)\n",
        "\n",
        "    # Create inverted labels for the fake samples\n",
        "    y_gan = np.ones((2 * batch_size, 1))\n",
        "\n",
        "    # Update the generator via the discriminator's error\n",
        "    with tf.GradientTape() as tape:\n",
        "      fake_imgs = self.generator(x_gan)\n",
        "      fake_imgs_and_labels = [fake_imgs, x_gan[1]]\n",
        "      predictions = self.discriminator(fake_imgs_and_labels)\n",
        "      g_loss = self.loss_fn(y_gan, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    # Monitor loss\n",
        "    self.gen_loss_tracker.update_state(g_loss)\n",
        "    self.disc_loss_tracker.update_state(d_loss)\n",
        "    self.fake_accuracy_tracker.update_state(0.0, fake_predictions)\n",
        "    self.real_accuracy_tracker.update_state(1.0, real_predictions)\n",
        "    return {metric.name: metric.result() for metric in self.train_metrics}\n",
        "\n",
        "  def build_discriminator(self, in_shape=(28, 28, 1), n_classes=10, label_embedding=50,\n",
        "                          conv1_channels=32, conv2_channels=64, dense_hidden=128, use_batchnorm=False):\n",
        "    # label input\n",
        "    i_label = Input(shape=(1, ))\n",
        "    x_label = Embedding(n_classes, label_embedding)(i_label)\n",
        "    x_label = Dense(in_shape[0] * in_shape[1], activation='tanh')(x_label)\n",
        "    x_label = Reshape((in_shape[0], in_shape[1], 1))(x_label)\n",
        "\n",
        "    # image input\n",
        "    i_img = Input(shape=in_shape)\n",
        "\n",
        "    # concatenate\n",
        "    x = Concatenate()([x_label, i_img])\n",
        "\n",
        "    # conv layers\n",
        "    x = Conv2D(conv1_channels, (3, 3), strides=(2, 2), padding='same', activation='tanh')(i_img)\n",
        "    x = Conv2D(conv2_channels, (3, 3), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(dense_hidden, activation='tanh')(x)\n",
        "    if use_batchnorm:\n",
        "      x = keras.layers.BatchNormalization()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model([i_img, i_label], x)\n",
        "    return model\n",
        "\n",
        "  def build_generator(self, latent_dim=50, n_classes=10, label_embedding=50,\n",
        "                      label_hidden=16, input_hidden=16,\n",
        "                      conv1_channels=128, conv2_channels=128):\n",
        "    # label input\n",
        "    i_label = Input(shape=(1, ))\n",
        "    x_label = Embedding(n_classes, label_embedding)(i_label)\n",
        "    x_label = Dense(7 * 7 * label_hidden, activation='tanh')(x_label)\n",
        "    x_label = Reshape((7, 7, label_hidden))(x_label)\n",
        "\n",
        "    # foundation for 7x7 image\n",
        "    i_lat = Input(shape=(latent_dim, ))\n",
        "    x_lat = Dense(7 * 7 * input_hidden, activation='tanh')(i_lat)\n",
        "    x_lat = Reshape((7, 7, input_hidden))(x_lat)\n",
        "\n",
        "    # concatenate\n",
        "    x = Concatenate()([x_lat, x_label])\n",
        "\n",
        "    # upsample to 14x14\n",
        "    x = Conv2DTranspose(conv1_channels, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "\n",
        "    # upsample to 28x28\n",
        "    x = Conv2DTranspose(conv2_channels, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "\n",
        "    # make only one color channel, values in (-1, +1)\n",
        "    x = Conv2D(1, (7, 7), activation='tanh', padding='same')(x)\n",
        "    return Model([i_lat, i_label], x)\n",
        "\n",
        "  def sample_images(self, e=0, b=0, method='show'):\n",
        "    if not os.path.exists('gan_images'):\n",
        "      os.makedirs('gan_images')\n",
        "\n",
        "    data, _ = self.generate_fake_samples(25)\n",
        "    imgs, labels = data\n",
        "    rows, cols = 5, 5\n",
        "\n",
        "    # Rescale images (-1, +1) -> (0, 1)\n",
        "    imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "    if method == 'show' or method == 'save':\n",
        "      fig, axs = plt.subplots(rows, cols, figsize=(9, 10))\n",
        "      idx = 0\n",
        "      for i in range(rows):\n",
        "        for j in range(cols):\n",
        "          axs[i, j].imshow(imgs[idx], cmap='gray')\n",
        "          axs[i, j].set_title(f'num: {labels[idx]}')\n",
        "          axs[i, j].axis('off')\n",
        "          idx += 1\n",
        "\n",
        "    if method == 'show':\n",
        "      plt.show()\n",
        "    elif method == 'save':\n",
        "      fig.savefig(f'gan_images/sample_{e:003d}_{b:0004d}.png')\n",
        "      plt.close()\n",
        "    elif method == 'wandb':\n",
        "      columns = ['epoch', 'batch', 'label_num', 'image']\n",
        "      im_table = wandb.Table(columns=columns)\n",
        "      for row in range(WANDB_IMAGE_NUM):\n",
        "        im_table.add_data(e, b, labels[row], wandb.Image(imgs[row]))\n",
        "      wandb.log({'generated_examples': im_table})\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(self, data):\n",
        "    gen_images_and_labels, _ = self.generate_fake_samples(VAL_METRIC_N_SAMPLE)\n",
        "\n",
        "    gen_images, gen_labels = gen_images_and_labels[0], gen_images_and_labels[1]\n",
        "    y_hat = self.val_model(gen_images, training=False)\n",
        "\n",
        "    self.is_tracker.update_state(y_hat)\n",
        "    self.bcis_tracker.update_state(y_hat, gen_labels)\n",
        "    self.wcis_tracker.update_state(y_hat, gen_labels)\n",
        "\n",
        "    return {metric.name: metric.result() for metric in self.val_metrics}\n",
        "\n",
        "  # save models\n",
        "  def save(self, filepath, overwrite=True, save_format=None, **kwargs):\n",
        "    self.generator.save(filepath + 'generator.h5')\n",
        "    self.discriminator.save(filepath + 'discriminator.h5')\n",
        "\n",
        "  # load models\n",
        "  def load_models(self, generator_path, discriminator_path):\n",
        "    self.generator = load_model(generator_path, compile=False)\n",
        "    self.discriminator = load_model(discriminator_path, compile=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ1kMQVxiDtv"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1hkIEkevKYg"
      },
      "source": [
        "## Define callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cRWbBqyldK81"
      },
      "outputs": [],
      "source": [
        "class SamplerCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, sample_freq: int=1):\n",
        "    super().__init__()\n",
        "    self.sample_freq = sample_freq\n",
        "    self.e = 0\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    self.e = epoch\n",
        "\n",
        "  def on_train_batch_end(self, batch: int, logs=None):\n",
        "    if batch % self.sample_freq == 0:\n",
        "      method = 'wandb' if USE_WANDB else 'save'\n",
        "      self.model.sample_images(self.e + 1, batch, method=method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M8OMtZrH3tNT"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LeIM45glKCL"
      },
      "source": [
        "# Hypermodel for hiperparameter optimization\n",
        "\n",
        "Sources:\n",
        "\n",
        "* [keras documentation for hyperparameter tuning with custom training loop](https://keras.io/guides/keras_tuner/custom_tuner/)\n",
        "* [kaggle notebook baout using keras-tuner with wandb](https://www.kaggle.com/code/aritrag/keras-tuner-with-wandb/notebook)\n",
        "* [keras documentation for keras-tuner Tuners](https://keras.io/guides/keras_tuner/getting_started/#tune-model-training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7RXsa5eOlKCL"
      },
      "outputs": [],
      "source": [
        "class CGANHypermodel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        config = {\n",
        "            'latent_dim': hp.Int('latent_dim', min_value=32, max_value = 128, step = 32),\n",
        "            'gen_label_embedding': hp.Choice('gen_label_embedding', [10, 25, 50]),\n",
        "            'gen_label_hidden': hp.Choice('gen_label_hidden', [1, 4, 8, 16, 32]),\n",
        "            'gen_input_hidden': hp.Choice('gen_input_hidden', [32, 64, 96]),\n",
        "            'gen_conv1_channels': hp.Choice('gen_conv1_channels', [16, 64, 128]),\n",
        "            'gen_conv2_channels': hp.Choice('gen_conv2_channels', [64, 128, 256]),\n",
        "            'disc_label_embedding': hp.Choice('disc_label_embedding', [10, 25, 50]),\n",
        "            'disc_conv1_channels': hp.Choice('disc_conv1_channels', [16, 64, 128]),\n",
        "            'disc_conv2_channels': hp.Choice('disc_conv2_channels', [64, 128, 256]),\n",
        "            'disc_dense_hidden': hp.Choice('disc_dense_hidden', [32, 64, 128]),\n",
        "            'disc_use_batchnorm': hp.Boolean('disc_use_batchnorm'),\n",
        "            'n_classes': hp.Fixed('n_classes', N_CLASSES),\n",
        "            'batch_size': hp.Fixed('batch_size', 32),\n",
        "            'n_val': hp.Fixed('n_val', VAL_METRIC_N_SAMPLE),\n",
        "            'VAL_MODEL_PATH': hp.Fixed('VAL_MODEL_PATH', VAL_MODEL_PATH),\n",
        "            'gen_learning_rate': hp.Fixed('gen_learning_rate', 0.0002),\n",
        "            'gen_adam_beta1': hp.Fixed('gen_adam_beta1', 0.5),\n",
        "            'discr_learning_rate': hp.Fixed('discr_learning_rate', 0.0002),\n",
        "            'discr_adam_beta1': hp.Fixed('discr_adam_beta1', 0.5),\n",
        "        }\n",
        "        # saving the keys to easily get config in fit()\n",
        "        self.last_build_config_keys = config.keys()\n",
        "        # building the CGAN\n",
        "        cgan = CGAN(config)\n",
        "        cgan.compile(\n",
        "            d_optimizer=Adam(learning_rate=config['discr_learning_rate'],\n",
        "                            beta_1=config['discr_adam_beta1']),\n",
        "            g_optimizer=Adam(learning_rate=config['gen_learning_rate'],\n",
        "                            beta_1=config['gen_adam_beta1']),\n",
        "            loss_fn=BinaryCrossentropy(from_logits=False)\n",
        "        )\n",
        "        return cgan\n",
        "\n",
        "    def get_current_config(self, hp):\n",
        "        return {key: hp.get(key) for key in self.last_build_config_keys}\n",
        "\n",
        "    def fit(self, hp, model, x, y, wandb_config, *args, **kwargs):\n",
        "        config = self.get_current_config(hp)\n",
        "        with wandb.init(project=PROJECT, config=config, mode=wandb_config['mode'],\n",
        "                        group=wandb_config['group']):\n",
        "            # defining callback, wandb callback is only possible after wandb.init\n",
        "            wandbcb = wandb.keras.WandbCallback(\n",
        "                monitor=\"val_within_class_inception_score\", mode=\"min\",\n",
        "                save_model=False, log_batch_frequency=50)\n",
        "            sampler = SamplerCallback(sample_freq=100)\n",
        "            garbage_collector = GarbageCollectorCallback()\n",
        "            # adding the callbacks to the automatic ones\n",
        "            kwargs['callbacks'].extend([sampler, garbage_collector, wandbcb])\n",
        "\n",
        "            ret = model.fit(x, y, *args,\n",
        "                            batch_size=config['batch_size'],\n",
        "                            **kwargs)\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh_tpTCRlKCM"
      },
      "outputs": [],
      "source": [
        "mode = None if USE_WANDB else 'disabled'\n",
        "group_name = 'hyperparam_optimization_hyperband_12_09_v3'\n",
        "wandb_config = {'mode': mode,\n",
        "                'group': group_name}\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    CGANHypermodel(),\n",
        "    objective=keras_tuner.Objective('val_within_class_inception_score', 'min'),\n",
        "    max_trials=20,\n",
        "    overwrite=True,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name=PROJECT,\n",
        ")\n",
        "\n",
        "# tuner = keras_tuner.Hyperband(\n",
        "#     CGANHypermodel(),\n",
        "#     objective=keras_tuner.Objective('val_within_class_inception_score', 'min'),\n",
        "#     factor=6,\n",
        "#     max_epochs=20,\n",
        "#     directory='hyperparam_tuning_hyperband_12_09_v3',\n",
        "#     project_name=PROJECT,\n",
        "# )\n",
        "\n",
        "tuner.search(x_train, labels_train,\n",
        "            wandb_config,\n",
        "            epochs=8, # only for RandomSearch\n",
        "            validation_data=[x_test[0]],\n",
        "            )\n",
        "\n",
        "print(tuner.get_best_hyperparameters()[0].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oczKQMMalKCM"
      },
      "source": [
        "# Create models and train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg4INiTPXUk9"
      },
      "outputs": [],
      "source": [
        "config = {'latent_dim': 96,\n",
        "          'gen_label_embedding': 10,\n",
        "          'gen_label_hidden': 8,\n",
        "          'gen_input_hidden': 96,\n",
        "          'gen_conv1_channels': 64,\n",
        "          'gen_conv2_channels': 64,\n",
        "          'disc_label_embedding': 10,\n",
        "          'disc_conv1_channels': 64,\n",
        "          'disc_conv2_channels': 128,\n",
        "          'disc_dense_hidden': 128,\n",
        "          'disc_use_batchnorm': False,\n",
        "          'n_classes': N_CLASSES,\n",
        "          'epochs': 10,\n",
        "          'batch_size': 32,\n",
        "          'n_val': VAL_METRIC_N_SAMPLE,\n",
        "          'VAL_MODEL_PATH': VAL_MODEL_PATH,\n",
        "          'gen_learning_rate': 0.0002,\n",
        "          'gen_adam_beta1': 0.5,\n",
        "          'discr_learning_rate': 0.0002,\n",
        "          'discr_adam_beta1': 0.5}\n",
        "mode = None if USE_WANDB else 'disabled'\n",
        "group_name = 'mnist_long'\n",
        "with wandb.init(project=PROJECT, config=config, mode=mode, group=group_name):\n",
        "    cgan = CGAN(config)\n",
        "\n",
        "    cgan.compile(\n",
        "        d_optimizer=Adam(learning_rate=config['discr_learning_rate'],\n",
        "                         beta_1=config['discr_adam_beta1']),\n",
        "        g_optimizer=Adam(learning_rate=config['gen_learning_rate'],\n",
        "                         beta_1=config['gen_adam_beta1']),\n",
        "        loss_fn=BinaryCrossentropy(from_logits=False)\n",
        "    )\n",
        "\n",
        "    wandbcb = wandb.keras.WandbCallback(monitor=\"val_within_class_inception_score\",\n",
        "                                        mode=\"min\", save_model=False, log_batch_frequency=50)\n",
        "    checkpointer = ModelCheckpoint(\n",
        "        'models/{epoch:002d}/', verbose=0, save_best_only=False,\n",
        "        save_weights_only=False, mode='auto', save_freq=1000)\n",
        "    sampler = SamplerCallback(sample_freq=1000)\n",
        "    garbage_collector = GarbageCollectorCallback()\n",
        "\n",
        "    cgan.fit(\n",
        "        x_train, labels_train,\n",
        "        epochs=config['epochs'],\n",
        "        batch_size=config['batch_size'],\n",
        "        validation_data=[x_test[0]], #dummy validation data\n",
        "        callbacks=[\n",
        "            checkpointer,\n",
        "            sampler,\n",
        "            garbage_collector,\n",
        "            wandbcb\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ZHXnriqKY-"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qgb0HIcqRb3"
      },
      "outputs": [],
      "source": [
        "e = 1\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ChrUTFTt4w3"
      },
      "outputs": [],
      "source": [
        "e = 3\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Flbu0EXt45-"
      },
      "outputs": [],
      "source": [
        "e = 5\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEy36lCwt49D"
      },
      "outputs": [],
      "source": [
        "e = 7\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df5J2Dyot5AR"
      },
      "outputs": [],
      "source": [
        "e = 9\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMMgM96Lt5DB"
      },
      "outputs": [],
      "source": [
        "e = 10\n",
        "cgan = CGAN(config)\n",
        "cgan.load_models(f'models/{e:02d}/generator.h5', f'models/{e:02d}/discriminator.h5')\n",
        "cgan.sample_images(method='show')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSbcTDPnjFur"
      },
      "source": [
        "# Download models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBIUzGa9S0sX"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/models.zip /content/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLeX1tpJjOcB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/models.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}