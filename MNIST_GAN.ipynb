{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FokaKefir/KepKreator/blob/main/MNIST_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# When runnning in colab\n",
        "#!pip install wandb\n",
        "#!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOixpLNLNLj5"
      },
      "source": [
        "# Import dependecies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I59B7OvNDTP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, Input, Flatten, Reshape, Embedding, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import wandb\n",
        "import sys, os\n",
        "\n",
        "VAL_MODEL_PATH = 'validation_cnn.hdf5' # todo reafactor this (two instances with wandb)\n",
        "PROJECT = 'KepKreator'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvAsA8tPhe_B"
      },
      "source": [
        "# Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BJrSWPQSG4h"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaYBacb7NKv9"
      },
      "outputs": [],
      "source": [
        "(x_train, labels_train), (x_test, labels_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0 * 2 - 1, x_test / 255.0 * 2 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekU665vsSN0S"
      },
      "source": [
        "## Plot some random examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hsozFwtXOaW4",
        "outputId": "8b21c9ac-cfb6-412b-86f8-1582afd00199"
      },
      "outputs": [],
      "source": [
        "def show_images(examples):\n",
        "  random_indices = np.random.choice(examples.shape[0], 9, replace=False)\n",
        "\n",
        "  # rescale images (-1, +1) -> (0, 1)\n",
        "  examples = 0.5 * examples + 0.5\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i, index in enumerate(random_indices, 1):\n",
        "      plt.subplot(3, 3, i)\n",
        "      plt.imshow(x_train[index], cmap='gray')\n",
        "      plt.title(f\"Label: {labels_train[index]}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "show_images(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation metrics for the generated images\n",
        "\n",
        "I found the following metrics:\n",
        "\n",
        "* inception score \n",
        "    * [medium article](https://medium.com/octavian-ai/a-simple-explanation-of-the-inception-score-372dff6a8c7a)\n",
        "    * [short code introduction](https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/)\n",
        "* parzen window estimation\n",
        "* conditional inception scores\n",
        "    * [Evaluation Metrics for Conditional Image Generation](https://arxiv.org/abs/2004.12361)\n",
        "* Frechet inception distance\n",
        "* kernel inception distance\n",
        "    * [KID code and GAN tips and trics](https://keras.io/examples/generative/gan_ada/#dataefficient-gans-with-adaptive-discriminator-augmentation)\n",
        "\n",
        "## Conditional inception scores and inception score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def kl_divergence(a, b):\n",
        "   '''Kullback-Leibler divergence\n",
        "   Smaller value means more similar distributions'''\n",
        "   a, b = np.atleast_2d(np.asarray(a)), np.atleast_2d(np.asarray(b))\n",
        "   eps = 1e-16\n",
        "   Dkls = a * np.log((a + eps) / (b + eps))\n",
        "   return Dkls.sum(axis=1)\n",
        "\n",
        "# seperately testable function calculating the metric\n",
        "def _bcis(y_hat, labels):\n",
        "    pG_y = np.expand_dims(y_hat.mean(axis=0), 0) # mean for all generated samples of pG_yx\n",
        "    \n",
        "    classes = np.unique(labels)\n",
        "    Dkl = np.ndarray(len(classes))\n",
        "    for i, cond in enumerate(classes):\n",
        "        # mean on classes of the pG_yx values\n",
        "        pG_yc = np.expand_dims(y_hat[labels == cond].mean(axis=0), 0)\n",
        "        Dkl[i] = kl_divergence(pG_yc, pG_y)[0]\n",
        "    return np.exp(Dkl.mean())\n",
        "\n",
        "# pG_yx is the predicted output by the baseline model\n",
        "def bcis_metric(model, inputs, labels):\n",
        "    '''Between-class inception score\n",
        "    Measures how close the representation of classes is to real data.\n",
        "    Higher BCIS is better, it indicates the distinct class representation\n",
        "    of the conditioned classes and a wide coverage across the conditional\n",
        "    classes, which is desired.\n",
        "    bcis = exp( Ec{ Dkl( pG_yc || pG_y ) } )'''\n",
        "    inputs, labels = np.asarray(inputs), np.asarray(labels)\n",
        "    y_hat = model.predict(inputs)\n",
        "    return _bcis(y_hat, labels)\n",
        "\n",
        "# seperately testable function calculating the metric\n",
        "def _wcis(y_hat, labels):\n",
        "    classes = np.unique(labels)\n",
        "    Dkl = np.ndarray(len(classes))\n",
        "\n",
        "    I = np.ndarray(len(classes))\n",
        "    for i, cond in enumerate(classes):\n",
        "        # mean of pG_yx with the given condition, as in BCIS\n",
        "        pG_yc = np.expand_dims(y_hat[labels == cond].mean(axis=0), 0)\n",
        "        # x is sampled from the given class\n",
        "        pG_yx = y_hat[labels == cond]\n",
        "        # kl divergence for each sample within the class\n",
        "        Dkl = kl_divergence(pG_yx, pG_yc)\n",
        "        I[i] = Dkl.mean(axis=0)\n",
        "    return np.exp(I.mean())\n",
        "\n",
        "def wcis_metric(model, inputs, labels):\n",
        "    '''Within-class inception score\n",
        "    Measures the quality and diversity for each of the classes.\n",
        "    High WCIS indicates a wide coverage of real classes within the \n",
        "    conditioned classes, which is an undesired property.\n",
        "    wcis = exp( Ec{ Dkl( pG_yx || pG_yc ) } )'''\n",
        "    inputs, labels = np.asarray(inputs), np.asarray(labels)\n",
        "    y_hat = model.predict(inputs)\n",
        "    return _wcis(y_hat, labels)\n",
        "\n",
        "def _inception_score(y_hat):\n",
        "    p_y = np.expand_dims(y_hat.mean(axis=0), 0)\n",
        "    # kl divergence for each image\n",
        "    Dkls = kl_divergence(y_hat, p_y)\n",
        "    return np.exp(Dkls.mean())\n",
        "\n",
        "# calculate the inception score for p(y|x)\n",
        "def inception_score_metric(model, inputs):\n",
        "    '''Inception score\n",
        "    IS = exp( Ex{ Dkl( pG_yx || pG_y ) } )'''\n",
        "    inputs = np.asarray(inputs)\n",
        "    y_hat = model.predict(inputs)\n",
        "    return _inception_score(y_hat)\n",
        "\n",
        "def get_metrics(model, inputs, labels):\n",
        "    '''Returns inception score, withing class inception score, \n",
        "    between class inception score '''\n",
        "    inputs, labels = np.asarray(inputs), np.asarray(labels)\n",
        "    y_hat = model.predict(inputs)\n",
        "    IS = _inception_score(y_hat)\n",
        "    bcis = _bcis(y_hat, labels)\n",
        "    wcis = _wcis(y_hat, labels)\n",
        "    return IS, wcis, bcis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHYedrdLhkmB"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdF01lCEhZlx"
      },
      "source": [
        "## Define Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5sqaSGtRdvX"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(config, in_shape=(28, 28, 1), n_classes=10):\n",
        "\n",
        "  # label input\n",
        "  i_label = Input(shape=(1, ))\n",
        "  x_label = Embedding(n_classes, 50)(i_label)\n",
        "  x_label = Dense(in_shape[0] * in_shape[1], activation='tanh')(x_label)\n",
        "  x_label = Reshape((in_shape[0], in_shape[1], 1))(x_label)\n",
        "\n",
        "  # image input\n",
        "  i_img = Input(shape=in_shape)\n",
        "\n",
        "  # concatenate\n",
        "  x = Concatenate()([x_label, i_img])\n",
        "\n",
        "  # conv layers\n",
        "  x = Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='tanh')(i_img)\n",
        "  x = Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(128, activation='tanh')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model([i_img, i_label], x)\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=Adam(config['discr_learning_rate'],\n",
        "                     beta_1=config['discr_adam_beta1']),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-Ruu9chooJ"
      },
      "source": [
        "## Define Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmsUQfYbJ6er"
      },
      "outputs": [],
      "source": [
        "def build_generator(latent_dim, n_classes=10):\n",
        "\n",
        "  # label input\n",
        "  i_label = Input(shape=(1, ))\n",
        "  x_label = Embedding(n_classes, 50)(i_label)\n",
        "  x_label = Dense(7 * 7 * 28, activation='tanh')(x_label)\n",
        "  x_label = Reshape((7, 7, 28))(x_label)\n",
        "\n",
        "  # foundation for 7x7 image\n",
        "  i_lat = Input(shape=(latent_dim, ))\n",
        "  x_lat = Dense(100 * 7 * 7, activation='tanh')(i_lat)\n",
        "  x_lat = Reshape((7, 7, 100))(x_lat)\n",
        "\n",
        "  # concatenate\n",
        "  x = Concatenate()([x_lat, x_label])\n",
        "\n",
        "  # upsample to 14x14\n",
        "  x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "\n",
        "  # upsample to 28x28\n",
        "  x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n",
        "\n",
        "  # make only one color channel, values in (-1, +1)\n",
        "  x = Conv2D(1, (7, 7), activation='tanh', padding='same')(x)\n",
        "  return Model([i_lat, i_label], x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N5n8kHhhsnv"
      },
      "source": [
        "## Define GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mERoHK9BLuQp"
      },
      "outputs": [],
      "source": [
        "def define_gan(generator, discriminator, config):\n",
        "  # make weights in the discriminator not trainable\n",
        "  discriminator.trainable = False\n",
        "\n",
        "  # get noise and label inputs from generator model\n",
        "  gen_lat, gen_label = generator.input\n",
        "\n",
        "  # get image output from the generator model\n",
        "  gen_output = generator.output\n",
        "\n",
        "  # connect image output and label input from generator as inputs to discriminator\n",
        "  gan_output = discriminator([gen_output, gen_label])\n",
        "\n",
        "  # define gan model as taking noise and label and outputting a classification\n",
        "  model = Model([gen_lat, gen_label], gan_output)\n",
        "\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=Adam(learning_rate=config['gan_learning_rate'],\n",
        "                     beta_1=config['gan_adam_beta1'])\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2wP8hVMhveD"
      },
      "source": [
        "## Real image sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qd0yoCxQu9r"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "  images, labels = dataset\n",
        "\n",
        "  ix = np.random.choice(labels.shape[0], n_samples)\n",
        "  x_imgs = images[ix]\n",
        "  x_labels = labels[ix]\n",
        "  y = np.ones((n_samples, 1))\n",
        "  return [x_imgs, x_labels], y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn6ZbscWh_rQ"
      },
      "source": [
        "## Lateint point generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGsSLXUeR5mE"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "  x_input = np.random.randn(latent_dim * n_samples)\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  x_labels = np.random.randint(0, n_classes, n_samples)\n",
        "  return [x_input, x_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6_YwoH1iBng"
      },
      "source": [
        "## Fake image generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHPaW1ImSUr7"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  # generate points in latent space\n",
        "  x_input, x_labels = generate_latent_points(latent_dim, n_samples)\n",
        "\n",
        "  # predict outputs\n",
        "  imgs = generator.predict([x_input, x_labels])\n",
        "\n",
        "  # create class labels\n",
        "  y = np.zeros((n_samples, 1))\n",
        "  return [imgs, x_labels], y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ1kMQVxiDtv"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZApCVNKifoP"
      },
      "source": [
        "## Fake image sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UndT_etmijOK"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('gan_images'):\n",
        "    os.makedirs('gan_images')\n",
        "\n",
        "def sample_images(generator, latent_dim, epoch=0, batch=0, method='show'):\n",
        "    WANDB_ROWS = 8\n",
        "    data, _ = generate_fake_samples(generator, latent_dim, 25)\n",
        "    imgs, labels = data\n",
        "    rows, cols = 5, 5\n",
        "\n",
        "    # Rescale images (-1, +1) -> (0, 1)\n",
        "    imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(9, 10))\n",
        "    idx = 0\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            axs[i, j].imshow(imgs[idx], cmap='gray')\n",
        "            axs[i, j].set_title(f'num: {labels[idx]}')\n",
        "            axs[i, j].axis('off')\n",
        "            idx += 1\n",
        "\n",
        "    if method == 'show':\n",
        "      plt.show()\n",
        "    elif method == 'save':\n",
        "      fig.savefig(f'gan_images/sample_e{epoch}_b{batch}.png')\n",
        "      plt.close()\n",
        "    elif method == 'wandb':\n",
        "      columns = ['epoch', 'batch', 'label_num', 'image']\n",
        "      im_table = wandb.Table(columns=columns)\n",
        "      for row in range(WANDB_ROWS):\n",
        "        im_table.add_data(epoch, batch, labels[row], wandb.Image(imgs[row]))\n",
        "      wandb.log({'generated_examples': im_table})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8MkPm1TpuOA"
      },
      "source": [
        "## Define train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw7OrdHnSYBY"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "def train_step(generator, discriminator, gan, dataset, config):\n",
        "  batch_size = config['batch_size']\n",
        "  half_batch = batch_size // 2\n",
        "  latent_dim = config['latent_dim']\n",
        "  # get randomly selected 'real' samples, with labels\n",
        "  x_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\n",
        "  # update discriminator model weights\n",
        "  d_loss_real, d_acc_real = discriminator.train_on_batch(x_real, y_real)\n",
        "  # generate 'fake' examples, with labels\n",
        "  x_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "\n",
        "  # update discriminator model weights\n",
        "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(x_fake, y_fake)\n",
        "\n",
        "  # calculate loss and accuracy\n",
        "  d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
        "  d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
        "\n",
        "  # prepare points in latent space as input for the generator, with\n",
        "  x_gan = generate_latent_points(latent_dim, batch_size)\n",
        "\n",
        "  # create inverted labels for the fake samples\n",
        "  y_gan = np.ones((batch_size, 1))\n",
        "\n",
        "  # update the generator via the discriminator's error\n",
        "  g_loss = gan.train_on_batch(x_gan, y_gan)\n",
        "  return d_acc, d_loss, g_loss\n",
        "\n",
        "def train(generator, discriminator, gan, dataset, config):\n",
        "  batch_size = config['batch_size']\n",
        "  n_val = config['n_val']\n",
        "  epochs = config['epochs']\n",
        "  latent_dim = config['latent_dim']\n",
        "  bat_per_epo = dataset[0].shape[0] // batch_size\n",
        "  half_batch = batch_size // 2\n",
        "  val_model = load_model(config['VAL_MODEL_PATH'])\n",
        "  # manually enumerate epochs\n",
        "  for epoch in range(epochs):\n",
        "    # enumerate batches over the training set\n",
        "    for b in range(bat_per_epo):\n",
        "\n",
        "      d_acc, d_loss, g_loss = train_step(generator, discriminator, gan, dataset, config)\n",
        "\n",
        "      # summarize loss on this batch\n",
        "      print(f'>{epoch + 1}/{epochs}, {b + 1}/{bat_per_epo}, d_loss={d_loss:.3f}, d_acc={d_acc:.3f} g_loss={g_loss:.3f}')\n",
        "      wandb.log({'epoch': epoch + 1,\n",
        "                 'batch': b+1,\n",
        "                 'd_loss': d_loss,\n",
        "                 'd_acc': d_acc,\n",
        "                 'g_loss': g_loss,})\n",
        "\n",
        "      if (b + 1) % 150 == 0:\n",
        "        sample_images(generator, latent_dim, epoch + 1, b + 1, method='wandb')\n",
        "        # if validaiton required\n",
        "        # generate images\n",
        "        (x_fake, y_fake), _ = generate_fake_samples(generator, latent_dim, n_val)\n",
        "        # calculate metrics on them\n",
        "        IS, wcis, bcis = get_metrics(val_model, x_fake, y_fake)\n",
        "        print(f'>{epoch+1/epochs}, {b + 1}/{bat_per_epo}, {bcis=}, {wcis=}, {IS=}')\n",
        "        wandb.log({'bcis': bcis,\n",
        "                   'wcis': wcis,\n",
        "                   'inception_score': IS})\n",
        "\n",
        "    generator.save(f'generator_{epoch + 1}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dClttQdMpxBu"
      },
      "source": [
        "# Create models and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WrBXpxoVsv_",
        "outputId": "db114000-bef2-4320-ee36-02ea48d31cc0"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "config = {'latent_dim': 100,\n",
        "          'epochs': 1,\n",
        "          'batch_size': 100,\n",
        "          'n_val': 1024,\n",
        "          'VAL_MODEL_PATH': 'validation_cnn.hdf5',\n",
        "          'gan_learning_rate': 0.0002,\n",
        "          'gan_adam_beta1': 0.5,\n",
        "          'discr_learning_rate': 0.0002,\n",
        "          'discr_adam_beta1': 0.5,\n",
        "          }\n",
        "wandb.init(project='KepKreator', config=config, mode='disabled')\n",
        "# size of the latent space\n",
        "latent_dim = wandb.config['latent_dim']\n",
        "\n",
        "# create the discriminator\n",
        "discriminator = build_discriminator(wandb.config)\n",
        "\n",
        "# create the generator\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "# create the gan\n",
        "gan = define_gan(generator, discriminator, wandb.config)\n",
        "\n",
        "# # train\n",
        "# train(\n",
        "#     generator,\n",
        "#     discriminator,\n",
        "#     gan,\n",
        "#     (x_train, labels_train),\n",
        "#     wandb.config\n",
        "# )\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypermodel for hiperparameter optimization\n",
        "\n",
        "Sources:\n",
        "\n",
        "* [keras documentation for hyperparameter tuning with custom training loop](https://keras.io/guides/keras_tuner/custom_tuner/)\n",
        "* [kaggle notebook baout using keras-tuner with wandb](https://www.kaggle.com/code/aritrag/keras-tuner-with-wandb/notebook)\n",
        "* [keras documentation for keras-tuner Tuners](https://keras.io/guides/keras_tuner/getting_started/#tune-endtoend-workflows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hp_to_config(hp):\n",
        "    keys = ['latent_dim', 'epochs', 'batch_size', 'n_val', 'VAL_MODEL_PATH',\n",
        "            'gan_learning_rate', 'gan_adam_beta1', 'discr_learning_rate', \n",
        "            'discr_adam_beta1']\n",
        "    config = {key: hp.get(key) for key in keys}\n",
        "    return config\n",
        "\n",
        "def build_hypermodels(hp):\n",
        "    config = {'latent_dim': hp.Int('latent_dim', min_value=64, max_value = 256, step = 64),\n",
        "        'epochs': hp.Fixed('epochs', 1),\n",
        "        'batch_size': hp.Fixed('batch_size', 100),\n",
        "        'n_val': hp.Fixed('n_val', 1024),\n",
        "        'VAL_MODEL_PATH': hp.Fixed('VAL_MODEL_PATH', 'validation_cnn.hdf5'),\n",
        "        'gan_learning_rate': hp.Fixed('gan_learning_rate', 0.0002),\n",
        "        'gan_adam_beta1': hp.Fixed('gan_adam_beta1', 0.5),\n",
        "        'discr_learning_rate': hp.Fixed('discr_learning_rate', 0.0002),\n",
        "        'discr_adam_beta1': hp.Fixed('discr_adam_beta1', 0.5),\n",
        "        }\n",
        "    discriminator = build_discriminator(config)\n",
        "    generator = build_generator(config['latent_dim'])\n",
        "    gan = define_gan(generator, discriminator, config)\n",
        "    return discriminator, generator, gan\n",
        "\n",
        "class MyTuner(keras_tuner.RandomSearch):\n",
        "    def run_trial(self, trial, dataset, *args, **kwargs):\n",
        "        # Get the hp from trial.\n",
        "        hp = trial.hyperparameters\n",
        "        discriminator, generator, gan = build_hypermodels(hp)\n",
        "        config = hp_to_config(hp)\n",
        "        val_model = load_model(config['VAL_MODEL_PATH'])\n",
        "        bat_per_epo = dataset[0].shape[0] // config['batch_size']\n",
        "        log_batch = bat_per_epo // 8\n",
        "        eval_batch = bat_per_epo // 3\n",
        "        d_acc, d_loss, g_loss = 0, 0, 0\n",
        "        EPOCHS = 3\n",
        "\n",
        "        wcis_list = []\n",
        "        run = wandb.init(project=PROJECT, config=hp.values)\n",
        "        for epoch in range(EPOCHS):\n",
        "            for batch in range(bat_per_epo):\n",
        "                da, dl, gl = train_step(generator, discriminator, gan, dataset, config)\n",
        "                d_acc += da\n",
        "                d_loss += dl\n",
        "                g_loss += gl\n",
        "                if batch % log_batch == 0:\n",
        "                    d_acc, d_loss, g_loss = d_acc / log_batch, d_loss / log_batch, g_loss / log_batch\n",
        "                    print(f'>{epoch + 1}/{EPOCHS}, {batch + 1}/{bat_per_epo}, '\n",
        "                          f'd_loss={d_loss:.3f}, d_acc={d_acc:.3f} g_loss={g_loss:.3f}')\n",
        "                    wandb.log({'epoch': epoch + 1,\n",
        "                                'batch': batch + 1,\n",
        "                                'd_loss': d_loss,\n",
        "                                'd_acc': d_acc,\n",
        "                                'g_loss': g_loss,})\n",
        "                    d_acc, d_loss, g_loss = 0, 0, 0\n",
        "                if batch % eval_batch == 0:\n",
        "                    (x_fake, y_fake), _ = generate_fake_samples(generator, config['latent_dim'], config['n_val'])\n",
        "                    # calculate metrics on them\n",
        "                    IS, wcis, bcis = get_metrics(val_model, x_fake, y_fake)\n",
        "                    wcis_list.append(wcis)\n",
        "                    print(f'>{epoch + 1}/{EPOCHS}, {batch + 1}/{bat_per_epo}, {bcis=}, {wcis=}, {IS=}')\n",
        "                    wandb.log({'bcis': bcis,\n",
        "                            'wcis': wcis,\n",
        "                            'inception_score': IS})\n",
        "        # Finish the wandb run\n",
        "        run.finish()        \n",
        "        # Return the objective value to minimize.\n",
        "        return max(wcis_list)\n",
        "\n",
        "\n",
        "tuner = MyTuner(\n",
        "    # No hypermodel or objective specified.\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_anything\",\n",
        ")\n",
        "\n",
        "# No need to pass anything to search()\n",
        "# unless you use them in run_trial().\n",
        "tuner.search((x_train, labels_train))\n",
        "print(tuner.get_best_hyperparameters()[0].values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ZHXnriqKY-"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "-qgb0HIcqRb3",
        "outputId": "e53ce97f-605d-491a-bfc9-02989a30c549"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_1.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "2ChrUTFTt4w3",
        "outputId": "27bdbb0a-d548-4a09-86e4-4412ac8c378b"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_4.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "_Flbu0EXt45-",
        "outputId": "7b62886b-12bd-4261-e498-a4544943617f"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_7.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "tEy36lCwt49D",
        "outputId": "ae7076f8-3b5d-41db-ebcd-2c556fba7fd4"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_10.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "Df5J2Dyot5AR",
        "outputId": "b7a34366-c578-4bbc-fc4f-23b28bae82c9"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_13.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "BMMgM96Lt5DB",
        "outputId": "91c81717-1906-402e-b590-232efcacc68c"
      },
      "outputs": [],
      "source": [
        "model = load_model('generator_16.h5')\n",
        "sample_images(model, latent_dim, method='show')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMBKj0v7tUSXUNAI8z6g39r",
      "collapsed_sections": [
        "ZdF01lCEhZlx"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
